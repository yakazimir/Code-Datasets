:see readingcommand to_fol()
parse the expression
remove length three and length two prefixes in this order
read a line of text decode it using this reader's encoding and return the resulting unicode string
:see expression _set_type()
return a static html page from the path given
return the tree positions in the trees which match the given pattern
:return a dictionary giving the 'standard' transcription for each word
open a new window containing a graphical diagram of this tree
creates a table of tokentablefields
this decorator defines __unicode__ method and fixes __repr__ and __str__ methods under python 2
an individual variable must be a single lowercase character other than 'e', followed by zero or more digits
self = (\x walk x subj -o f
constructs an arff_formatter instance with class labels and feature types determined from the given data
decode a reference encoded with reference encode
:return the given file s as a list of chunks each of which is a list of words and punctuation symbols
:see expression _set_type()
uses data that has been gathered in training to determine likely collocations and sentence starters
given a featureset label pair return the corresponding vector of joint-feature values
:see expression findtype()
returns a tuple of the html page built and the new current word
process length six patterns and extract length four roots
convert a list of tagged tokens to a chunk-parse tree
load a valuation from a persistent database
:see expression visit()
check to make sure that all of the cfg productions are potentially useful
create a new minimal set
read a block from the input stream
illustrate the various methods of discoursetester
:return the given file s as a list of chapters each encoded as a list of sentences which are
returns the probability of the given symbol sequence if the sequence
determines the best word alignment for one sentence pair from the corpus that the model was trained on
if the variable can be replaced with other a substitution is returned
this function returns the total mass of probability transfers from the seen samples to the unseen samples
find instances of the regular expression in the text
:return a list of the productions for which reductions are available for the current parser state
initialize probability tables to a uniform distribution derived classes should implement this accordingly
templates can have more than a single feature
determines the best word alignment for one sentence pair from the corpus that the model was trained on
helper used to implement the view methods -- returns a list of words or a list of sentences optionally tagged
:return the number of entries in the table used by this tagger to map from contexts to tags
:see multilistbox itemconfigure()
:return the canvas that this canvas widget is bound to
return the parse trees currently contained in the chart
return an iterable of the feature identifiers used by this featstruct
modify _eval_chunk to try to keep the amount of time that the eval demon takes between _eval_demon_min and _eval_demon_max
construct a new frequency distribution if samples is
satisfiers of an open formula in a first order model
attempt to make a boolean expression if the next token is a boolean
check whether the alignments are legal
return this edge's left-hand side which specifies what kind of structure is hypothesized by this edge
adds an arc from the node specified by head_address to the node specified by the mod address
note that the algorithm for left-arc is quite similar except for precondition for both arc-standard and arc-eager
return a formatted representation of this chunkstring
attempt to unify fval1 and and fval2, and return the resulting unified value
train on sentence_aligned_corpus and create a lexical translation model
return the trigrams generated from a sequence of items as an iterator
:return whether the word in position j of the target
return a pretty-printed string representation of this chart's leaves
implements step 1c from "an algorithm for suffix stripping"
return true if the positions of this feature intersects with those of other more precisely return true if this feature refers to the same property as other
return lemmas of the given language as list of words
sort the elements and subelements in order specified in field_orders
returns a list of all frames that contain lus in which the name attribute of the lu matchs the given regular expression
return a string representation of this rule it has the form :
determine if input contains negation words
returns the set of indices *i* such that applicable_rules(token i
construct a bigramcollocationfinder for all bigrams in the given sequence
return the frequency count for this lemma
find the most general unification of the two given expressions
read up to size bytes from the underlying stream decode them using this reader's encoding and return the resulting
return a list of pcfg probabilisticproductions
return true if all lexical rules are "preterminals", that is unary rules which can be separated in a preprocessing step
toggle displaying of the relation types for the given synset
return 18 templates from the original nltk demo and additionally a few
returns the html string for one synset or word
return a list concatenating other with self
convert a mace4-style relation table into a dictionary
generate an input file for tadm based on the given corpus of classified tokens
:see expression constants()
configure this widget this is equivalent to
create a new box widget
a demonstration showing how cfgs can be created and used
parse the subscripts for a primitive category
read a file into memory and convert each relation clause into a list
register a hierarchical child widget the child will be
build a list of semantic readings for a sentence
try to build a nltk sem valuation
print the contents of this canvasframe to a postscript file
implements the block comparison method
:see expression _set_type()
:return the meaning's expressions as a dictionary whose keys are language variety uniform identifiers and whose values are lists of expression
return the base frequency distribution that this probability distribution is based on
apply self prob_classify() to each element of featuresets i e :
:see baseprovercommand decorate_proof()
wrap the first of 'lines' with textwrap and the remaining lines at exactly the same positions as the first
helper function which returns the type feature of the item,
mark the location of an error in a line
distance metric comparing set-similarity
find the type of the given variable as it is used in this expression
extract dependency triples of the form
:return the given file s as a list of words and punctuation symbols
uses a set of tagged data to train the tagger
:param root the root directory for this corpus
register a new callback that will be called after this canvaswidget is dragged
apply inference rules to distribute semtypes over relations between fes
determines the approximate score for translating the
an event variable must be a single lowercase 'e' character followed by zero or more digits
create a new shiftreduceparser, that uses grammar to parse texts
constructs a contingencymeasures given a ngramassocmeasures class
a list of the names of the columns in this table
convert a list of strings into a canonical symbol
python port of the moses detokenizer
returns the state sequence of the optimal most probable path through the hmm
return true if the item is a terminal which currently is if it is hashable and not a nonterminal
return the contents of the corpus readme txt file
begin parsing the given tokens
initialize a discoursetester
return the strategy used by this parser
the key function that creates a randomized initial distribution that still sums to 1
return a list concatenating self with other
display a single-line representation of this feature structure suitable for embedding in other representations
from an association measure function produces a new function which accepts contingency table values as its arguments
call mace4 to build a model for each current discourse thread
set distortion probabilities uniformly to
update the probability for the given sample this may cause the object
a demonstration for the regexpchunkparser class a single text is
:return a probability distribution over sets of labels for the given featureset
handle a motion event
:return the xml description for the given roleset
override counter __setitem__() to invalidate the cached n
recalculates abbreviations given type frequencies despite no prior determination of abbreviations
:rtype tree :return the tree that is licensed by production
davies and fleiss 1982 averages over observed and expected agreements for each coder pair
return a constant describing the status of the given package or collection
open a standard format marker file for sequential reading
create a new chunk parser from the given start state and set of chunk patterns
the means used for clustering
return a string with markers surrounding the matched substrings
scores bigrams using chi-square i e phi-sq multiplied by the number
create a new space widget
lexicographic exemplar sentences optionally filtered by lu name and/or 1-2 fes that are realized overtly
given a text returns a list of the start end spans of sentences in the text
:param xs a list of symbol value pairs
:param root the root directory for the corpus
inverts a directed graph
induce a pcfg grammar from a list of productions
one left & one right token both case-normalized skip over
validate date limits
computes the probability of all possible word alignments expressed as a marginal distribution over target words t
return a string representation of the model
adds the logged values returning the logarithm of the addition
tags each sentence in a list of sentences
:param expression the expression to handle
serializes the learned tagger to a file in pickle format reloads it and validates the process
:param devset_name the name of the development set used for display & for save files
both the antecedent and consequent of 'self' and 'other' must unify
return the id of the synset
use mace4 to build a first order model
remove a hierarchical child widget this child will no longer
return a list of all wordnet identifiers that appear in any class or in classid if specified
the non-negative constant that all encoded feature vectors will sum to
construct a new aligned corpus reader for a set of documents located at the given root directory
returns words in specified fileids
:return mark slot at position as occupied
obtain details for a specific frame
merge sort split the list in half and sort each half then combine the sorted halves
helper for build_index(): yield a list of elementtree element
return true if self subsumes other i e return true
mainly included for backwards compat
split the frequency distribution in two list r nr where nr r > 0
:param count value to add to the vacancy counts
normalize the string value in an rte pair's value or entailment attribute as an integer 1 0
@return the given token's text
return true if the right-hand contain at least one terminal token
use maltparser to parse multiple pos tagged sentences takes multiple
print a string representation of this freqdist to 'stream'
:see abstractexpression get_refs()
stem a dutch word and return the stemmed form
pretty-print this tree as ascii or unicode art
pretty print a sequence of data items
display the command line help message
implements step 2 from "an algorithm for suffix stripping"
scott 1955 here multi-pi
construct a new chinkrule
:param parsed_sents the list of parsed_sents as the output of parser
helper function for pretty-printing a semantic type
remove all elements and subelements with no text and no child elements
convert this split disjunction to conjunctive normal form cnf
populate a dictionary of bigram features reflecting the presence/absence in the document of each of the tokens in bigrams
get the height of a line of text
a demonstration showing the creation of a dependencygrammar in which a specific number of modifiers is listed for a given
builds a trie object which is built around a defaultdict if strings is provided it will add the strings, which
get yesterday's datetime as a 5-tuple
configure nltk's java interface by letting nltk know where it can find the java binary and what extra options if any should be
identify appropriate csv writer given the python version
change the child widget contained by this container widget
:param readings readings to combine
:param data bytes to write to file or buffer
:param variable variable, for the variable
randomly sample the hmm to generate a sentence of a given length this
return the best chunk structure for the given tokens and return a tree
create a recursive descent parser demo using a simple grammar and text
find the given resource by searching through the directories and zip files in paths where a none or empty string specifies an absolute path
return the region rv that is used by the french stemmer
:param fileids a list or regexp specifying the fileids that have to be returned as a raw string
illustrate the various methods of discoursetester
modify and return the proof string
builds a lambda function representing a predicate on a tree node from the conjunction of several other such lambda functions
return the dictionary mapping r to nr the number of samples with frequency r where nr > 0
a demonstration of the result of aligning phonetic sequences used in kondrak's 2002 dissertation
frame annotation sets matching the specified criteria
computes the probability of all possible word alignments expressed as a marginal distribution over target words t
:return a corpus view that acts as a list of nombankinstance objects one for each noun in the corpus
a binding is consistent with the dict if its variable is not already bound or if its variable is already bound to its argument
:param labels a list of all class labels that can be generated
return a string containing a pretty-printed representation of the given verbnet class
read a sequence of s-expressions from the stream and leave the stream's file position at the end the last complete s-expression
:see readingcommand combine_readings()
return a list of the absolute paths for all fileids in this corpus or for the given list of fileids if specified
an improvement over functools update_wrapper the wrapper is a generic
parses a stream of tokens and splits it into sentences (using c{soft_delimiter} tokens) and blocks (using c{hard_delimiter} tokens) for use with the l{align_texts} function
:param int limit the number of data items to process in the current round of processing
highlight the given item
return a list of features one for each start point in starts and for each window length in winlen
return all the lemma_names associated with the synset
:return the number of rows that makes up one page
lin similarity return a score denoting how similar two word senses are based on the
the set of all roots of this tree this set is formed by
return 37 templates taken from the postagging task of the fntbl distribution http //www
build a list of rtepairs from a rte corpus
try to find a space for a given widget
compiles and returns a regular expression to find contexts including possible sentence boundaries
returns a freqdist containing only data with counts below a given threshold as well as a mapping (none -> count_removed)
return a string containing a pretty-printed representation of the given verbnet frame
return vowel weight if p is vowel
:return a list of the hierarchical children of this canvas widget
simple equality test
use the simplified :class twitter class to write some tweets to a file
:param fileid the name of the underlying file
divides the text into pseudosentences of fixed size
normalises the vector to unit length
create a new container widget this constructor should only
read this file's contents decode them using this reader's encoding and return it as a list of unicode lines
load single n-gram language file given the iso 639-3 language code
this is the top-lebel node in a tgrep2 search string the predicate function it returns binds together all the state of a
compute the max depth for the given part of speech this is
try all possible ways of plugging a single hole
:see expression free()
check for logical equivalence
a demonstration of the chart parsers
store content in filename can be used to store a sentimentanalyzer
:return the given file s as a list of words and punctuation symbols
union is the maximum of value in either of the input counters
create a new probabilistic dependency parser no additional
add a binding to each tkinter label and tkinter listbox
true if the token is either a number or is alphabetic
identifier of the predicate
print trace output displaying the given stack and text
return all sentences in the corpus
initialize a variable selects a new identifier
return the grammar productions filtered by the left-hand side or the first item in the right-hand side
:rtype featstruct :return the feature structure that is obtained by deleting
:param provercommand provercommand to decorate
return the grammar productions filtered by the left-hand side or the first item in the right-hand side
return a pair consisting of a starting category and a list of productions
calculate brevity penalty
>>> from nltk corpus import framenet as fn
:return a list of lists of word/tag/iob tuples
get the translations for a source language phrase
return the sentence alignment of two text blocks usually paragraphs
:return a concise string representatino of the dependencyspan
returns all possible skipgrams generated from a sequence of items as an iterator
return the list *tr*, where *tr[r]* is the total count in heldout_fdist for all samples that occur *r*
builds a lambda function representing a predicate on a tree node which describes the use of a previously bound node label
bubble sort compare adjacent elements of the list left-to-right and swap them if they are out of order
construct a new expandrightrule
union is the maximum of value in either of the input counters
display a friendly error message when parsing a tree string fails
smoothing method 4 shorter translations may have inflated precision values due to having
create a shift reduce parser app using a simple grammar and text
removes the node with the given address references
:see expression negate()
add counts from two conditionalfreqdists
applies the tag method over a list of sentences this method will return
this function provides a demonstration of the snowball stemmers
enter the tkinter mainloop this function must be called if
a simple demonstration showing how to use canvas widgets
compute the overlap between text and hypothesis
tags a single sentence
scores ngrams using likelihood ratios as in manning and schutze 5 3 4
using the streaming api select just the tweets from a specified list of userids
try some proofs and exhibit the results
unmark an edge or all edges
map the xml input into an rtepair
convert a file of prolog clauses into a database table
stem a word using the lancaster stemmer
issues a reminder to users following the book online
use the rest api to search for past tweets by a given user
:see expression replace()
print a list of all templates ranked according to efficiency
return the cfg corresponding to the input string s
collects training data from a given text if finalize is true it
score the accuracy of the chunker against the gold standard
predicate to check whether obj is a nltk tree tree
return all the reviews as a list of review objects if fileids is
this function is a fast way to calculate binomial coefficients commonly known as nck i
return a new unique variable
rename all occurrences of the variable introduced by this variable binder in the expression to newvar
returns the set of all nodes that are after the given node
construct a new wordnet corpus reader with the given root directory
generate the productions that correspond to the non-terminal nodes of the tree
load an annotation set from a sentence in an subcorpus of an lu
apply the chunk parser to this input
return a string containing a pretty-printed representation of the given verbnet class's thematic roles
:rtype list str :return the document that this concordance index was
skolemize clausify and standardize the variables apart
print trace output displaying that a token has been shifted
returns the distance of the shortest path linking the two synsets if one exists
implements step 1a from "an algorithm for suffix stripping"
toggle the display of the relations for the given synset and relation type
creates the mutable probdist based on the given prob_dist and using the list of samples given
construct a bigramcollocationfinder given freqdists for appearances of words and possibly non-contiguous bigrams
return a html unordered list of synsets for the given word and part of speech
tokenize a string to split off punctuation other than periods
call with specified tags as a list e g tags=['subst', 'comp']
the zipfile zipfile object used to access the zip file
:param function expression for the function
create an instance of the lancaster stemmer
return weighted sum of difference between p and q
return the bottom-rightmost point without actually drawing the item
if the feature with the given name or path exists return its value otherwise raise keyerror
:param sentence_aligned_corpus parallel corpus under consideration
yields pairs of tokens from the given iterator such that each input token will appear as the first element in a yielded tuple
take an id and return the synsets
compute the transitive closure of a graph represented as a linked list
return a list of feature-based productions
change the text that is displayed by this text widget
return the number of samples with count r
plot the given samples from the conditional frequency distribution
use stanfordparser to parse multiple sentences takes multiple sentences
from iddo lev's phd dissertation p108-109
this just assumes that words in all caps or titles are named entities
return 24 templates of the seminal tbl paper brill 1995
if the path is not absolute guess that it is a subdirectory of the user's home directory
:return the most appropriate label for the given featureset
:return a bounding box for this canvaswidget the bounding
:return true if method overrides some method with the same name in a base class
sort the rows in this table using the specified column's values as a sort key
scores ngrams by pointwise mutual information as in manning and schutze 5
:return a corpus view that acts as a list of propbankinstance objects one for each noun in the corpus
create a new symbol widget
:return the given file s as a list of sentences each encoded as a list of word tag tuples
scores bigrams using dice's coefficient
helper function for pretty-printing a frame element
given an exemplar sentence and a set of fe names return the subset of fe names that are realized overtly in the sentence on the fe fe2 or fe3 layer
if there is a substitution corresponding to this variable return the substituted category
returns the list of all nodes descended from the given node where there is only a single path of descent
construct a new sentiwordnet corpus reader using data from the specified file
scores ngrams using pearson's chi-square as in manning and schutze 5
:see expression _set_type()
exemplify repr rule (see also str rule and rule format("verbose"))
if the feature with the given name or path exists return its value otherwise return default
return a string representation of the model
returns the similarity score for two ngrams
initialize the crfsuite tagger
return true if x is a node label or hole in this semantic representation
:return the given file s as a list of tagged words and punctuation symbols encoded as tuples
return a multiline string where each line contains a word tag and iob tag
check if we should add or remove any rules from consideration given the changes made by *rule*
returns all the tree positions in the given tree which are not leaf nodes
return a string representation for this corpus view that is similar to a list's representation but if it would be more
:see expression visit()
bennett albert and goldstein 1954
execute an sql query over a database
group a chunk structure into a list of 'semi-relations' of the form (list str tree)
use boxer to give a first order representation
:return the given file s as a list of tagged chunks represented in tree form
helper for build_index(): perform some checks to make sure that the given package is consistent
:return a verbose string representation of the dependencyspan
write out a grammar file ignoring escaped and empty lines
:param c the correction constant the value of the correction
set the node label this will only succeed the first time the
parse the next complete expression from the stream and return it
set the node label to label
:return the feature weight vector for this classifier
applies the tag method over a list of sentences this method will return a
call the rest api 'search/tweets' endpoint with some plausible defaults
enable or disable warnings of data integrity issues as they are encountered
construct a new mtecorpusreader for a set of documents located at the given root directory
display a multi-line representation of this feature dictionary as an fvm feature value matrix
return a set of all keywords used in the corpus
add a binding to all tree segments
returns the node label used to begin a tgrep_expr_labeled see
remove all objects from the resource cache
stem a german word and return the stemmed form
return a list of context-free productions
handle a release callback - unregister motion & button release callbacks
produce a giza-formatted string representing the alignment
general purpose decorator factory takes a caller function as input and returns a decorator with the same attributes
use nltk's currently recommended named entity chunker to chunk the given list of tagged tokens
return the xml info record for the given item
perform the actual model building
load a given resource from the nltk data package the following
:return svg representation of a tree
return an open file pointer for the data file for the given part of speech
count ui oi pairs for truncation points until we find the segment where ui oi crosses the truncation line
:param labels a list of the "known labels" for this encoding
load frame-relation element and its child fe-relation elements from frrelation xml
attempt to build a model store the result to prevent unnecessary
check whether there are cycles
:param index the index of the first leaf in the tree
position this table's main frame widget in its parent widget
:return a list of all labels that are attested in the given list of tokens
decode the given byte string into a unicode string using this reader's encoding
builds a lambda function representing a predicate on a tree node which can optionally bind a matching node into the tgrep2 string's
extracts and returns the attributes of the given element
multiply every thread in discourse by every reading in readings
return the target category for the parser
construct a new chart display
process length four patterns and extract length three roots
:see abstractexpression get_refs()
given a file object containing a list of tweet ids fetch the corresponding full tweets from the twitter api
return an iterator that returns the next field in a marker value tuple
construct a new chunkrulewithcontext
:return the cmudict lexicon as a list of entries containing word transcriptions tuples
return a buffered gzip file object
create a new dependency grammar from the set of productions
convert the data in a nodelist into a networkx labeled directed graph
return the list *estimate*, where *estimate[r]* is the probability estimate for any sample that occurs *r* times in the base frequency
return the *i* th token in the corpus file underlying this corpus view
returns all the possible categories for a word
parse a grammar rule given as a string and return a list of productions
given a text generates the sentences in that text annotates all
:param frame optional frame object name or id only relations involving
:return a set of all the lists of children that cover span and that match rhs
custom display location can be prefix or slash
returns the score for a given trigram using the given scoring function
load this corpus if it has not already been loaded this is
helper function -- return a copy of list with all elements of type cls spliced in rather than appended in
check to make sure that s still corresponds to some chunked version of _pieces
:param drs drtexpression, the drs to be drawn
construct a trigramcollocationfinder given freqdists for appearances of words bigrams two words with any word between them
remove the given child canvas widget child's parent will
helper function for pretty-printing an exemplar sentence for a lexical unit
ascii string rendering of the sentence along with its targets and frame names
finds the difference between the values in ranks1 and ranks2 for keys present in both dicts
separate the string for the next portion of the category from the rest
return the backward probability matrix a t by n array of log-probabilities where t is the length of the sequence and n is the
:return the given file s as a list of paragraphs each encoded as a list of sentences which are
return true if the given edge overlaps with any edge on the given level
:see abstractexpression get_refs()
move a token from the beginning of remaining_text to the end of stack
returns score of a substitution of p with q
returns the score for a given bigram using the given scoring function
construct and return new feature encoding based on a given training corpus train_toks
assumes that each line in stream is a json-serialised object
register a method for handling tweets
:return timestamped file name
a function that will just compute log-likelihood estimate in the original paper it's described in algorithm 6 and 7
draws and outputs in png for ipython
return a string representation of this freqdist
look up the alignments that map from a given index or slice
return the region r1 that is used by the scandinavian stemmers
initialize a new element wrapper for etree
set the probability associated with this object to prob
remove a canvas widget from this canvasframe this
:see abstractexpression get_refs()
convenience function for authentication
return all sentences in the corpus or in the specified files/categories
in the pl196x corpus each category is stored in single file and thus both methods provide identical functionality
:return the grammar used by this parser
return the start index of this edge's span
return the number of edges contained in this chart
parse a string representing a category and returns a tuple with
trains the brill tagger on the corpus *train_sents*, producing at most *max_rules* transformations each of which
use maltparser to parse multiple sentences
a demonstration of the probabilistic parsers the user is
attempt to make an application expression if the next tokens
return a list of the 'most informative' features used by this classifier
:return the given file s as a dict of (corpus_property_key value)
convert a chunk-parse tree to a list of tagged tokens
a demonstration showing the creation and use of a dependencygrammar to perform a projective dependency
return true if this non-terminal is equal to other in
use production to combine the rightmost stack elements into a single tree
probability of target sentence and an alignment given the
return the value of a row or a cell in this table if
:return a corpus view that acts as a list of strings one for each line in the predicate-argument annotation file
prints some information about this corpus
return the regions rv and r2 which are used by the russian stemmer
find contexts where the specified words appear list most frequent common contexts first
the absolute path identified by this path pointer
true if the token text is all alphabetic
return a list of file identifiers for the fileids that make up this corpus
:param sent : list of words remaining in the sentence
:see expression constants()
train on sentence_aligned_corpus and create a lexical translation model vacancy models a fertility model and a
:param dep_graph the representation of an input in the form of dependency graph
use stanford tokenizer's ptbtokenizer to tokenize multiple sentences
tag tokenized sentences
return the height of the tree
return the value by which counts are discounted by default set to 0 75
constructor usr' is a sem expression representing an
:param binding_list list of (abstractvariableexpression, atomicexpression) to initialize the dictionary
return a string representation of this rule it has the form :
get the information content of the least common subsumer that has the highest information content value
classify 10000 positive and negative tweets using vader approach
:param fileid the name of the underlying file
return the grammar used by this parser
count error-rate relative to truncation errt
:param title the title of the review
:param load load the pickled model upon instantiation
load a given chart into the chart parser
return true if this production is equal to other
return the value s of the specified row s if last is
return an index of the annotated documents in framenet
plug the nodes in queue' with the labels in potential_labels'
returns the log probability of the two sentences c{source_sents[i]}, c{target_sents[j]} being aligned with a specific c{alignment}
the mode of the underlying stream
parses and tokenizes if necessary a tgrep search string into a lambda function
:param root the root directory for this corpus
:param probdist_dict a dictionary containing the probdists indexed
default value for this feature
:param valuation_str str with the model builder's output
decode the result of model_found()
add a binding to all nodes
create a new chart parser that uses grammar to parse texts
:see abstractexpression get_refs()
load full annotation info for a document from its xml file
header_mode a stream backed corpus view specialized for use with
:return the given file s as string or int
:param other bindingdict the dict with which to combine self
return the overall f measure for all texts that have been scored by this chunkscore
probability of target sentence and an alignment given the
takes a list of nodes that have been identified to belong to a cycle and collapses them into on larger node
construct a new non-terminal from the given symbol
:see expression findtype()
sort the given queue of edges in descending order of the inside probabilities of the edges' trees
:return the hierarchical parent of this canvas widget
return a string representation of this conditionalprobdist
return a list concatenating self with itself count times
scores ngrams using the poisson-stirling measure
a helper function that instantiates bncwordviews or the list of words/sentences
helper function for pretty-printing a frame relation
:param src_sentence sentence to be translated
close a previously opened standard format marker file or string
returns the log-probability of the given symbol sequence if the
:rtype list tree
return the expression to which 'variable' is bound
:return an iterator over synset objects that are either proper hypernyms or instance of hypernyms of the synset
return a tokenized copy of *text* see :class regexptokenizer
return the probability associated with this object
true if the token text is that of a number
write twitter data as line-delimited json into one or more files
ipython magic : show svg representation of this alignedsent
convert this pointer to a standard 'tree position' pointer given that it points to the given tree
return all words in the opinion lexicon note that these words are not
:return beta-converted version of this expression
:param expression a skolemized expression in cnf
return a correctly ordered list if words
exemplify rule format("verbose")
create a new iterator over this list starting at the given offset
construct a new splitrule
apply the stemming rule to the word
check the arity of a relation
distance metric that takes into account partial agreement when multiple labels are assigned
:return the given file s as a list of paragraphs each encoded as a list of sentences which are
returns header s of specified fileids
construct a new production
set the log probability associated with this object to logprob
return a tokenized copy of *s*
build a list of concepts corresponding to the relation names in items
writes arff data to a file for the given data
return the set of discourse referents in this drs
add blank elements and subelements specified in default_fields
import the module on demand and get the attribute
add a new canvas widget to the scroll-watcher the
use self _sentences to construct a value for self _readings
compute the pk metric for a pair of segmentations a segmentation is any sequence over a vocabulary of two items (e
return a string representation of this probdist
determine which contexts occurred with enough distinct targets
starting from the alignment in alignment_info, look at neighboring alignments iteratively for the best one according
>>> from nltk parse import dependencygraph dependencyevaluator
return a generator that will add all edges licensed by this rule given the edges that are currently in the
return true if the grammar is of chomsky normal form i e all productions
get rid of punctuation except apostrophes
re-draw the table from scratch by clearing out the table's multi-column listbox and then filling it in with values from
convert logic expression to prover9 formatted string
get the path s from this synset to the root where each path is a list of the synset nodes traversed on the way to the root
:return an iterator of the parses that have been found by this parser so far
sort the children of elem
:see expression constants()
helper function which returns the type feature of the item,
creates lambda values based upon training data
:param fileids a list specifying the fileids that should be used
use a grammar with binding operators to parse a sentence
given a new edge recalculate
parse an application operator
update this canvas widget in response to a change in one of its children
process length five patterns and extract length four roots
use boxer to give a first order representation
group words by stems defined by truncating them at given length
builds a punkt model and applies it to the same text
a helper function for select, which creates a new index for a given set of attributes aka restriction keys
return true if a feature with the given name or path exists
return a new path pointer formed by starting at the path identified by this pointer and then following the relative
:return whether the proof was successful or not
construct a new table widget
:param modelbuildercommand modelbuildercommand to decorate
apply this rule at every position in positions where it applies to the given sentence
classifies the token into a cluster setting the token's cluster parameter to that cluster identifier
python port of the moses tokenizer
apply self classify() to each element of featuresets i e :
returns a sequence of ngrams ordered by decreasing score whose scores each exceed the given minimum score
count understemmed and overstemmed pairs for lemma stem pair with common words
create a new scroll-watcher widget
remove entities from text by converting them to their corresponding unicode character
parses a string with one test sentence per line
use repp to tokenize a single sentence
calculates values of a quadgram contingency table from marginal values
for classes that was fixed with @python_2_unicode_compatible unicode_repr returns obj
selection sort scan the list to find its smallest element then swap it with the first element
return the feature structure that is obtained by deleting any feature whose value is a variable
read input expressions and provide a handler for satisfy that blocks further propagation of the undefined error
use tree read(s remove_empty_top_bracketing=true) instead
:see multilistbox show_column()
:return the dendrogram representing the current clustering
return the leaf value of the word at the given index
:param data response from twitter api
smoothing method 3 nist geometric sequence smoothing the smoothing is computed by taking 1 / 2^k ), instead of 0 for each
given a set of reference values and a set of test values return the fraction of test values that appear in the reference set
convert a list of concept objects into a list of label extension pairs optionally create a valuation object
return a list of all edges in this chart new edges
:return the context that should be used to look up the tag for the specified token or none if the specified token
:param name the name of the variable
return a string representation of this rule it has the form :
string representation of the lexicon used for debugging
update the rule data tables to reflect the fact that *rule* applies at the position * sentnum wordnum *
:return the meaning's source id
replace -> with arrows and colorize the entire buffer
intersection is the minimum of corresponding counts
returns true given a token and the token that preceds it if it seems clear that the token is beginning a sentence
:param x this cell's x coordinate
process length six patterns and extract length three roots
return the package or collection record for the given item
returns the euclidean distance between vectors u and v this is equivalent
a module to convert the a pos tagged document stream (i
:return a list of all the productions for which expansions are available for the current parser state
just for testing
close the underlying stream
return a list of text colortag tuples that make up the colorized representation of the item
given a method function return a new method function that first checks if self
if the feature with the given name or path exists delete its value otherwise raise keyerror
:return true if the item is a nonterminal
enter the tkinter mainloop this function must be called if
the right sibling of this tree or none if it has none
re classifies each given token if - it is period-final and not a known abbreviation or
print the list of the current assumptions
return all comparisons in the corpus
a word type is counted as a rare abbreviation if
return a html page of nltk browser format constructed from the
the default directory to which packages will be downloaded
call the binary with the given input
removes leading and trailing puncutation leaves contractions and most emoticons
return a list of fileids that make up this corpus if
classifies the token into a cluster returning a probability distribution over the cluster identifiers
classifies candidate periods as sentence breaks yielding a dict for each that may be used to understand why the decision was made
:return the width of this canvas widget's bounding box in its canvas's coordinate space
return the sample's probability
make a binary concept out of the primary key and another field in a record
create a copy of this frequency distribution
access the relevant time offset
:rtype list int :return a list of the offset positions at which the given
:return the given file s as a list of words and punctuation symbols
rename all occurrences of the variable introduced by this variable binder in the expression to newvar
this is the word rank alignment algorithm described in the paper to produce the *worder* list i
returns false if the client should stop fetching tweets
arrange the child widgets of this canvas widget this method
add more data to the concept's extension set
use stanfordparser to parse multiple sentences takes multiple sentences as a
return the frequency distribution that this probability distribution is based on
initialize the thesaurus
create a new feature list with the specified features
use :module twittercorpusreader tp read a file of tweets and print out * some full tweets in json format
returns the set of all nodes descended in some way through left branches from this node
:param labels a list of the "known labels" for this encoding
make sure that a given plugging is legal we recursively go through
if an integer or float begins at the specified position in the given string then return a tuple (val end_position)
return the classifier that this tagger uses to choose a tag for each word in a sentence
return the tree nodes in the trees which match the given pattern
returns text as a list of sentences
return a sequence of relative spans given a sequence of spans
:param modelbuilder the theorem tool to execute with the assumptions
given a text returns a list of the sentences in that text
return internal crubadan code based on iso 639-3 code
note that the algorithm for shift is the same for arc-standard and arc-eager
return the contents of license for omw
scores ngrams using the jaccard index
the tree position of this tree relative to the root of the tree
enter the tkinter mainloop this function must be called if
change the grammar used to parse texts
retract assumptions from the assumption list
returns true if word[i] is a consonant false otherwise a consonant is defined in the paper as follows
add a multi-word expression to the lexicon stored as a word trie we use util
make this feature structure and any feature structure it contains immutable
returns the entropy over labellings of the given sequence this is
make a tag dictionary for single-tag words
:return the given file s as a list of sentences each encoded as a shallow tree
tabulate the given samples from the conditional frequency distribution
translate one entity to its iso latin value
smoothing method 1 add *epsilon* counts to precision with 0 counts
load fe coreset info from xml
return the proof string
:see expression replace()
assign individual constants to the individuals in the domain of a valuation
try some proofs and exhibit the results
update the parent pointer of child to not point to self this
a timer decorator to measure execution performance of methods
find contexts where the specified words can all appear and return a frequency distribution mapping each context to the
:param binary if true then treat all feature/value pairs as individual binary features rather than using a single n-way
pretty printing for assignments {'x', 'u'} appears as 'g[u/x]'
train a new conditionalexponentialclassifier, using the given training samples using the improved iterative scaling algorithm
add root if necessary to specified fileid
analyze the sentence string to figure out how big a unit needs to be how big the tree should be etc
reads a custom tab file containing mappings of lemmas in the given language to princeton wordnet 3
the feature/s of a template takes a list of positions relative to the current word where the feature should be
process some tweets in a simple manner
:param root the root directory for this corpus
the number of texts in the corpus divided by the number of texts that the term appears in
print collocations derived from the text ignoring stopwords
:return the text contents of the given fileids as a single string
return a string representation of this probdist
wrapper for 'statuses / filter' api call
:param lemmas a dictionary where keys are lemmas and values are sets or lists of words corresponding to that lemma
return true if the right-hand side only contains nonterminals
load full info for a lexical unit from its xml file
construct a trigramcollocationfinder for all trigrams in the given sequence
return all words and punctuation symbols in the corpus or in the specified files/categories
return the ordered list of transformation rules that this tagger has learnt
return the ratio by which counts are discounted on average c*/c
each token should be a pos-tagged word
constructs a bigram collocation finder with the bigram and unigram data from this finder
add a new item to the minimal set having the specified context target and display form
concatenates the two spans in whichever way possible this
trains the hmm using the baum-welch algorithm to maximise the probability of the data sequence
plot a learning curve -- the contribution on tagging accuracy of the individual rules
build a reference to a new page
returns the number of left children under the node specified by the given address
returns a case-normalized representation of the token
return the frequency count for this lemma
return a list of supported languages as iso 639-3 codes
turn dependency graphs into nltk trees
identifies boundaries at the peaks of similarity score
generate a lexical dispersion plot
return the set of labels which are not referenced directly as part of another formula fragment
create a new canvas widget this constructor should only be
return the model builder object
:return the previous cept of j, or none if j belongs to
assigns a score to every edge in the dependencygraph graph
a module to find repp tokenizer binary and its *repp set* config file
find the copula+'van' relation ('of') in the dutch tagged training corpus from conll 2002
add new assumptions to the assumption list
produce a plot showing the distribution of the words through the text
return all sentences in the corpus or in the specified files
scores ngrams using student's t test with independence hypothesis for unigrams as in manning and schutze 5
return a list of the indices where this tree occurs as a child of parent
construct and return new feature encoding based on a given training corpus train_toks
read from stream until we find at least one element that matches tagspec, and return the result of applying
output polarity scores for a text using vader approach
a method that calculates the order of the columns that senna pipeline will output the tags into
initialize the corpus reader categorization arguments
this function finds the reference that is the closest length to the hypothesis
extract the unique counter from the url if it has one otherwise return
calculates the corpus level chrf character n-gram f-score it is the micro-averaged value of the sentence/segment level chrf score
compiles and returns a regular expression for word tokenization
ensure correct typing across a collection of expression objects
calculate a single corpus-level bleu score aka system-level bleu for all
get the path s from this synset to the root counting the distance of each node from the initial node on the way
return the bottom-rightmost point without actually drawing the item
:return the given file s as a list of sentences each encoded as a list of chunks
concatenate together the contents of multiple documents from a single corpus using an appropriate concatenation function
fully connects all non-root nodes all nodes are set to be dependents
:return the given file s as a list of tagged words and chunks
check whether the grammar rules cover the given list of tokens
call the candc binary with the given input
:return the set of variables used by this feature structure
this is a python port of the penn treebank tokenizer adapted by the moses machine translation community
move the read pointer forward by offset characters
if possible return a single value if not return
apply self tag() to each element of *sentences* i e :
return the sample with the greatest number of outcomes in this frequency distribution
print out a mace4 model using any mace4 interpformat format
return the list of words and constituents considered as clues of a comparison (from listofkeywords
the name of the roleset used by this instance's predicate
converts the pairs generated by tree2semi_rel into a 'reldict': a dictionary which stores information about the subject and object nes plus the filler between them
make a valuation from a list of relation metadata bundles and dump to persistent database
add a binding to all leaves
return relevant features for segment comparsion
print the list of the current assumptions
move the file position forward by offset characters ignoring all buffers
:return the result of applying elementtree tostring() to
this is a factory method that instantiates and returns a subtype of abstractvariableexpression appropriate for the given variable
tokenizes a tgrep search string into separate tokens
perform the actual proof store the result to prevent unnecessary
:rtype iter tree :return an iterator of all parses that can be generated by
:return a verbose string representation of this regexpchunkparser
apply self prob_classify() to each element of featuresets i e :
attempt to arrange words into a letter-grid with the specified number of rows and columns
add a binding to this table's main frame that will call func in response to the event sequence
return n-gram freqdist for a specific language
count the number of times this word appears in the text
returns the number of sentence breaks marked in a given set of augmented tokens
map a corpus file to its web version on the childes website and open it in a web browser
return the bigrams generated from a sequence of items as an iterator
change the height of this space widget
load the info for a frame from a frame xml file
return a float for sentiment strength based on the input text
the dependency graph in conll format
return a string representation of this chunkstring
:return a list of all variables in this object
:return a partial structure for the text that is currently being parsed
return a string representation of this rule it has the form :
adjust the scrollregion of this scroll-watcher's canvas to include the bounding boxes of all of its children
extract phrases from all_phrases_from that contains words
call the mace4 binary with the given input
collapse subtrees with a single child ie unary productions
create a new data xml index file by combining the xml description
pick an alphabetic character as identifier for an entity in the model
return the right-hand side of this production
returns difference between phonetic segments p and q for feature f
return the current file position on the underlying byte stream
:see expression _set_type()
run nltk wordnet browser server
determine an appropriate tag for the specified token and return that tag
:param fileids a list specifying the fileids that should be used
implements step 4 from "an algorithm for suffix stripping" step 4
:return the given file s as a list of paragraphs each encoded as a list of sentences which are
enter the tkinter mainloop this function must be called if
:return the tree position of the lowest descendant of this tree that dominates self
:param goal input expression to prove :type goal sem
:param antecedent expression for the antecedent
read a line in a valuation file
return the absolute path for the given file
helper function for pretty-printing a list of annotated sentences for a full-text document
:param variable variable, for the variable
:param goal input expression to prove :type goal sem
given a tagged sentence return an untagged version of that sentence
construct a new rule that changes a token's tag from c{original_tag} to c{replacement_tag} if all of the properties
:return a dictionary mapping something
construct a tnt statistical tagger tagger must be trained
return the feature structure that is obtained by replacing each feature structure value that is bound by bindings with the
calculates values of a contingency table from marginal values
convert this expression into a first-order logic expression
return a human-readable string representation for this alignedsent
the ribes rank-based intuitive bilingual evaluation score from hideki isozaki tsutomu hirao kevin duh katsuhito sudoh and
use the lidstone estimate to create a probability distribution for the experiment used to generate freqdist
exemplify repr rule (see also str rule and rule format("verbose"))
trains a dependencyscoreri from a set of dependencygraph objects and establishes this as the parser's scorer
gets the string value of a given parse tree node for comparison using the tgrep node literal predicates
return a list of the feature paths of all features which are assigned incompatible values by fstruct1 and fstruct2
:returns a set of all conditions for rules that are applicable to c{tokens[index]}
set the selected row if index is specified then select
:param status_code the status code returned by the twitter api
:return the given file s as a list of sentences each encoded as a list of word strings
builds a dictionary structure which defines the given macro
write the binary features to input file and update the transition dictionary
a module to convert a single pos tagged sentence into conll format
initialize the multi-word tokenizer with a list of expressions and a
returns the list of all nodes which are descended from the given tree node in some way
use nltk's currently recommended part of speech tagger to tag the given list of sentences each consisting of a list of tokens
return a list concatenating other with self
set of free variables
collects training data from a given list of tokens
calculates the depth of each gap i e the average difference
match the first element of the frontier in particular if
return the contents of citation bib file for omw
returns a padded sequence of items before ngram extraction
if an integer begins at the specified position in the given string then return a tuple (val end_position) containing the
applies the first applicable suffix-removal rule to the word takes a word and a list of suffix-removal rules represented as
return the static web help page
create a new context-free grammar from the given start state and set of productions
implements step 5a from "an algorithm for suffix stripping"
return a pretty-printed string representation of this chart
stem a finnish word and return the stemmed form
returns the list of all nodes dominating the given tree node
helper used to implement the view methods -- returns a list of tokens segmented words chunks or sentences
construct a new multi-column listbox widget
a demo showing the training and use of a projective dependency parser
train and test a classifier on instances of the subjective dataset by pang and lee
it is necessary to renormalize all the probability estimates to ensure a proper probability distribution results
return the upper frame page if with_shutdown is true then a 'shutdown' button is also provided
produce a giza-formatted string representing the alignment
:param fileids a list specifying the fileids that should be used
returns score of an indel of p
enter the tkinter mainloop this function must be called if
return a generator that adds edges to the chart one at a time
color in an edge with the given colors
enter the tkinter mainloop this function must be called if
replaces all accented letters on a word with their non-accented counterparts
return the contents of the corpus readme txt or readme file
check whether a feature is informative
return true if this list contains value
return all positive words in alphabetical order
register a canvas widget with this canvasframe the
return the contents of the corpus readme txt file
return a seekable read-only stream that can be used to read the contents of the file identified by this path pointer
create a new canvasframe
block reader for timit tagged sentences which are preceded by a sentence number that will be ignored
:return the value of the attribute attr see the class
given a text generates the sentences in that text by only testing candidate sentence breaks
given a thread id find the list of logic expression objects corresponding to the reading ids in that thread
get synset relations data for a synset note that this doesn't
insert a child canvas widget before a given index
retrieve the mapping dictionary between tagsets
convert string representation into a lexicon for ccgs
:param phrase_table table of translations for source language phrases and the log probabilities for those translations
stem a french word and return the stemmed form
builds a lambda function representing a predicate on a tree node depending on its relation to other nodes in the tree
return the left-hand side of this production
convert defaultdict to common dict representation
non-interactive demonstration of the clusterers with simple 2-d data
configure the table cell at the given row and column valid
create a new stack widget
the synset key is the unique name of the synset this can be retrived via synset
starting from the alignment in alignment_info, look at neighboring alignments iteratively for the best one
perform a single parsing operation if an untried match is
return uncurried base-function
check for logical equivalence
a string representation of the token that can reproduce it with eval(), which lists all the token's non-default
parse csv file containing tweets and output data a list of text label tuples
convert data read from stdout/stderr to unicode
construct a quadgramcollocationfinder given freqdists for appearances of words bigrams trigrams two words with one word and two words between them three words
return the set of child pointer lists for the given edge
return log p , where p is the probability associated with this object
perform the actual word stemming
return a copy of this edge's bindings dictionary
lookup 'key' there should be exactly one item in the associated relation
return the chart rule used to generate the most recent edge
updates the edge scores to reflect a collapse operation into new_node
find all synsets that are hypernyms of this synset and the other synset
:return true if this canvas widget is hidden
get the static index page
calculates the kendall's tau correlation coefficient given the *worder* list of word alignments from word_rank_alignment(), using the formula
convert this pointer to a standard 'tree position' pointer given that it points to the given tree
currently unimplemented because the neural dependency parser and the stanfordcorenlp pipeline class doesn't support passing in pre-
create and return a wrapper around a given element object
return the length of this edge's span
calculates values of contingency table marginals from its values
:return the given file s as a list of sentences or utterances each encoded as a list of word
note that the algorithm for reduce is only available for arc-eager
enter the tkinter mainloop this function must be called if
returns the set of all nodes that are before the given node
finds the best alignment according to ibm model 2
replace all instances of variable v with expression e in self where v is free in self
a demonstration of the porter stemmer on a sample from the penn treebank corpus
:return the size of the fixed-length joint-feature vectors that are generated by this encoding
return the offsets of the tokens in *s*, as a sequence of start end tuples by splitting the string at each successive match of *regexp*
krippendorff's interval distance metric >>> from nltk
this function returns the complete pos tuple for the partial pos tuple given to it
:param generic a meaning formula string containing the
:return a concise string representation of this chunk regexpparser
normalize the boundaries identified to the original text's
pack this canvasframe see the documentation for
set the http proxy for python to download through
a demonstration of the result of reading a dependency version of the first sentence of the penn treebank
:param function expression, for the function expression
creates the sentence alignment of two texts
given a set of reference values and a set of test values return the f-measure of the test values when compared against the
compute the alignment of two phonetic strings
insert a child canvas widget before a given index
configure all table cells in the given row valid keyword
parses a list of tokens in accordance to the mst parsing algorithm for non-projective dependency parses
stem an hungarian word and return the stemmed form
:return the given file s as a list of paragraphs each encoded as a list of sentences which are
:see readingcommand parse_to_readings()
ascii string rendering of the sentence along with a single target and its fes
evaluate and print classifier performance on the test set
:see expression constants()
apply self parse() to each element of sents
:param fileids a list specifying the fileids that should be used
set the value for the feature with the given name or path to value
collapse subtrees with a single child ie unary productions
return a list of the transformational rules that would correct the *i*th subtoken's tag in the given token
:param gramfile name of file where grammar can be loaded
return a new nonterminal whose symbol is a/b, where a is the symbol for this nonterminal and b is the symbol for rhs
creates an em clusterer with the given starting parameters convergence threshold and vector mangling parameters
return a list of the categories that are defined for this corpus or for the file s if it is given
returns true if the given text includes a sentence break
:return a tuple of words for the specified fileids
set the value by which counts are discounted to the value of discount
return this edge's dot position which indicates how much of the hypothesized structure is consistent with the
:return ascii art for a discontinuous tree
remove connective  if it precedes a word beginning with 
use prover9 to prove a theorem
:param normalise should vectors be normalised to length 1
apply self tokenize() to each element of strings i e :
this module returns a list of characters from the perl unicode properties
return an iterator that generates the tokens in the corpus file underlying this corpus view
removes alignments from alignment_infos that have
the childes corpus should be manually downloaded and saved
add a binding to each tkinter listbox widget in this
:return the given file s as a list of words and punctuation symbols
:return the name of the symbol that is displayed by this symbol widget
execute the given java command by opening a subprocess that calls java
decorates a class to register it's json tag
return a matrix of transition log probabilities
return a string representation of this probdist
return this edge's right-hand side which specifies the content of the structure hypothesized by this edge
traverse the nodes of a tree in breadth-first order
rename auto-generated unique variables
:rtype list str :return the document that this context index was
this method modifies the tree in three ways 1
return a string representation of this probdist
function to remove punctuation from unicode string
return the node label of the tree
register a method for handling tweets
generates an iterator of all sentences from a cfg
a demonstration of frequency distributions and probability distributions
destroy this widget and the associated menu
return a list concatenating self with other
insert a new row into the table so that its row index will be row_index
write the output of an analysis to a file
set up any colortags that will be used by this colorized list
parse a primitive category if the primitive is the special category 'var', replace it with the
return a list of the leaf values of each word in the chart's sentence
>>> from nltk corpus import wordnet as wn
:type graph dependencygraph
create a new feature-based grammar from the given start state and set of productions
return the bounding box for the given table cell relative to this widget's top-left corner
initialize the tag position mapping & the rule related mappings
:return a list of the tree locations of all subtrees that have not yet been expanded and all leaves that have not
this method serves as a hook for other logic parsers that
return an iterator that generates this feature structure and each feature structure it contains
return a list concatenating other with self
returns score of an expansion/compression
print trace output displaying that production was used to reduce stack
create a new oval widget
return a string representation of this rule
convert json file to csv file preprocessing each row to obtain a suitable dataset for tweets semantic analysis
a tuple containing the names of the columns used by this multi-column listbox
:return the given file s as a list of sentences or utterances each encoded as a list of word
returns the list of all nodes dominating the given node where there is only a single path of descent
:param root the root directory for this corpus
update the parent pointer of child to point to self this
:return the given file s as a list of tagged words and punctuation symbols encoded as tuples
:param lists the underlying lists
returns an iterator over the edges in this chart
return a string representation of this probdist
return the contents of the corpus license file if it exists
the name of this feature
read a bracketed tree string and return the resulting tree
generates of ngram score pairs as determined by the scoring function provided
append 'item' to the list at 'key' if no list exists for 'key', then
create a dictionary of predicates from the assumptions
returns a list of human-readable strings indicating the errors in the given tagging of the corpus
removes candidate ngrams which have frequency less than min_freq
:see expression visit()
return true if there are no empty productions
return all words and punctuation symbols in the corpus
construct a new concordance index
when python is run from within the nltk/ directory tree the current directory is included at the beginning of the search path
:param raw_score likelihood of hypothesis so far
return a collection of the most recent tweets posted by the user
:param root the root directory for the corpus
is self of the form "pro x "?
convert the conll iob format to a tree
copy the given resource to a local file if no filename is
return the set of all categories for which the given category is a left corner
use simple linear regression to tune parameters self _slope and
helper function given a regexp match return a string of spaces that's the same length as the matched string
remove the given child canvas widget child's parent will
a demonstration of the recursive descent parser
handle a drs condition
return true if this feature structure is immutable feature
if this canvaswidget has a drag callback then call it otherwise find the closest ancestor with a click callback and
transform the model into various mace4 interpformat formats
a generator that implements the actual parsing algorithm
:see multilistbox columnconfigure()
:return the given file s as a list of paragraphs each encoded as a list of sentences which are
return a list of features each feature is a tuple made of the specific
parse the current contents of the textwidget buffer to create a list of productions
return the standard interpretations of the string regions r1 and r2
calculates the sentence level chrf character n-gram f-score described in - maja popovic
convert lexicon file to a dictionary
return a string representation of the model
builds a lambda function representing a predicate on a tree node which returns true if the node is located at a specific tree
build a new classifier based on the given training data *tagged_corpus*
return all the lemma objects associated with the synset
replace any feature structure that has a forward pointer with the target of its forward pointer to preserve reentrancy
return an iterator over the edges in this chart it is
calculate modified ngram precision
return an iterable of fid fval pairs where fid is a feature identifier and fval is the corresponding feature
calculate and return all the legal pluggings mappings of labels to holes of this semantics given the constraints
load a subcorpus of a lexical unit from the given xml
return the final parse chart from which all possible parse trees can be extracted
update the feature weights
the cache is a tuple p o x s where - s maps symbols to integers
calculates values of contingency table marginals from its values
return all tokenized sentences in the review
probability that word t in the target sentence is aligned to
:return a corpus view that acts as a list of all noun lemmas in this corpus (from the nombank
a list of restrictions on the combinators
return the alignment error rate aer of an alignment with respect to a "gold standard" reference alignment
return an open stream that can be used to read the given file
return the number of words in this chart's sentence
construct a new maxent classifier model typically new
the frequency of the term in text
stem a russian word and return the stemmed form
perform the first pass of annotation which makes decisions based purely based on the word type of each word
:return a list of lines composing a string representation of this feature dictionary
set the level of tracing output that should be generated when parsing a text
helper for _annotation_ascii_fes()
convert a set containing individuals strings or numbers into a set of unary tuples
uncurry this application expression
return the true probability distribution for the experiment _create_rand_fdist numsamples x
return the hole that will be the top of the formula tree
use self _readings to construct a value for self _threads
create a new text widget
return true if self and other are both feature structures assign the same values to all features and contain the same
:see multilistbox hide_column()
return the length of the right-hand side
process length five patterns and extract length three roots
constructs a collocation finder given a collection of documents each of which is a list or iterable of tokens
given a long verbnet class identifier (eg 'confess-37 10'),
create a text object
change the strategy that the parser uses to decide which edges to add to the chart
return the chunk structure encoded by this chunkstring
:return the given file s as a list of the text content of tweets as as a list of words screenanames hashtags urls and punctuation symbols
maps the tag from the source tagset to the target tagset
return the chunks which were included in the guessed chunk structures listed in input order
extracts corpus/document info from the fulltextindex xml file
add a binding to all tree segments
this module symmetrisatizes the source-to-target and target-to-source word alignment output and produces aka
returns a view specialised for use with particular corpus file
convert an adjacency linked list back into a set of pairs
print the available template sets in this demo with a short description"
:raise notimplementederror openondemandzipfile is read-only
helper function for __init__: read the grammar if it is a string
given a list of relation metadata bundles make a corresponding dictionary of concepts indexed by the relation name
create a new corpus view that reads the pickle corpus fileid
restore selection & color configuration information that was saved using _save_config_info
replace every binding
this function "calculates ribes for a system output hypothesis with multiple references and returns "best" score among multi-references and
return the contents of toolbox settings file with a nested structure
when updating scores the score of the highest-weighted incoming arc is subtracted upon collapse
returns only the text content of tweets in the file s :return the given file s as a list of tweets
create a new path pointer pointing at the specified entry in the given zipfile
removes candidate ngrams w1 w2 where any of (fn w1 fn w2
return a list of file identifiers for the files that make up this corpus
:return the log probability of the symbol being observed in the given
:see expression visit_structured()
create lexical cfg rules for each individual symbol
:return the length of the shortest hypernym path from this synset to the root
run exists demos
:param featstruct the value of the sem node in a tree from
return most common top_n word features
given the original text and the list of augmented word tokens construct and return a tokenized list of sentence strings
brill tagger demonstration
return a concise representation of this chunkscoring
intersection is the minimum of corresponding counts
:return a multi-line string representation of this confusion matrix
train classifier on the training set optionally saving the output in the file specified by save_classifier
returns sentences in specified fileids
use the heldout estimate to create a probability distribution for the experiment used to generate base_fdist and
generic filter removes ngrams from the frequency distribution if the function returns true when passed an ngram tuple
create a new frequency distribution with random samples the
wrapper for 'statuses / sample' api call
read a giza-formatted string and return an alignment object
:return a concise string representation of this chartcell
return true if a feature with the given name or path exists
returns the likelihood of the vector belonging to the cluster
get the details for the specified frame using the frame's id number
pre-calculate of which form s the grammar is
return a skolem function over the variables in univ_scope
given a set of reference values and a set of test values return the fraction of reference values that appear in the test set
return a new copy of self the new copy will not be frozen
pick an alphabetic character as identifier for an entity in the model
trains a naivebayesclassifier using the edges present in graphs list as positive examples the edges not present as
returns a representation of the tree compatible with the latex qtree package
:return the input string that should be provided to the prover9 binary
corpus reader designed to work with national corpus of polish
return the number of times this list contains value
start parsing a given text this sets the parser's tree to
a module to find pre-trained maltparser model
:see multilistbox bind_to_labels()
tags by applying each rule to the entire corpus rather than all rules to a single sequence
:return the given file s as a list of paragraphs each encoded as a list of sentences which are
redirects arcs to any of the nodes in the originals list to the redirect node address
:return the portion of the text that is not yet covered by the stack
divide the given text into tokens using the punkt word segmentation regular expression and generate the resulting list
transliterate a russian word back into the cyrillic alphabet
:return the given file s as a list of sentences or utterances each encoded as a list of word
return a list of file identifiers for the files that make up this corpus or that store the given document s if specified
creates an information content lookup dictionary from a corpus
factory for creating defaultdict of defaultdict dict s
extract basic features about this word including - current word
stem a spanish word and return the stemmed form
helper for build_index(): given an xml elementtree, modify it and its descendents text and tail attributes to generate
count intersection between two line segments defined by coordinate pairs
given a sequence yields each element with an increasing rank suitable for use as an argument to spearman_correlation
returns true if the graph contains a node with the given node address false otherwise
add a binding to all leaves
carry out s-retrieval of binding operators in store if hack=true
access a lexical unit by its id luname frameid and framename are used
helper that selects the appropriate fileids for a given set of documents from a given subcorpus pos or psd
this function generates the maltparser command use at the terminal
pick an alphabetic character as identifier for an entity in the model
return a chunk structure containing the chunked tagged text that is encoded in the given ieer style string
true if the token text is that of an initial
:return the number of times that value li was expected and value lj was given
given a list of reference values and a corresponding list of test values return the fraction of corresponding values that are
a demonstration showing the creation and inspection of a dependencygrammar
true if the token text is that of an ellipsis
find the index of the first occurrence of the word in the text
re-download any packages whose status is stale
calculates expected values for a contingency table
recursively visit subexpressions apply 'function' to each
calculate the transitive closure of a directed graph optionally the reflexive transitive closure
performs token-based classification over a pair of contiguous tokens updating the first
interpretation of closed expressions in a first-order model
:return a tuple of synonym word pairs
this method serves as a hook for other logic parsers that
return a list of all verb lemmas that appear in any class or in the classid if specified
calculates values of a bigram contingency table from marginal values
return a string representation of this rule it has the form :
construct a new edge if the edge is incomplete (i e if
attempts to realign punctuation that falls after the period but should otherwise be included in the same sentence
returns the annotated document whose id number is fn_docid
use the lazymap class to construct a lazy list-like object that is analogous to map(feature_func toks)
construct and show the readings of the discourse or of a single sentence
:param goal input expression to prove :type goal sem
:return the xml description for the given roleset
return a list of all samples that occur once hapax legomena
return the line from the file with first word key
implements condition *o from the paper from the paper
returns words in specified fileids
load the pickled model weights
any subclass of feature must define static method extract_property tokens index
convert a tree between different subtypes of tree cls determines
calculate a single corpus-level gleu score aka system-level gleu for all
use the rest api to search for past tweets containing a given keyword
event handler for clicking on a column label -- sort by that column
set the value of the attribute attr to value see the
search for a jar that is used by nltk
caclculate age in months from a string in childes format
:param refs list of drtindividualvariableexpression for the
:return the given file s as a list of tagged words and punctuation symbols encoded as tuples
:return the portion of the text that is not yet covered by the tree
this method is intended to be overridden for logics that
replace every instance of variable with expression across every atom
returns true if stem contains a vowel else false
return true iff self and other have equal values
initialize the chatbot pairs is a list of patterns and responses each
:rtype str :return a string representation of this probdist
:param show all neg or pos for negative-only or positive-only
print trace output displaying the fringe of tree the
return an iterator of the complete tree structures that span the entire chart and whose root node is root
return the method resolution order for cls -- i e a list
begin dragging this object
:return a list of the canvas tags for all graphical elements managed by this canvas widget including
:return the object that is obtained by replacing each variable bound by bindings with its values
given a file object containing a list of tweet ids fetch the corresponding full tweets if available
finds the n-groups of items leaves reachable from a cut at depth n
return the feature detector that this tagger uses to generate featuresets for its classifier
:see expression free()
return a dependency graph for the sentence
select pairs of organizations and locations whose mentions occur with an intervening occurrence of the preposition "in"
assigns the vectors to clusters learning the clustering parameters from the data
determine the neighbors of alignment_info, obtained by
return an iterator that generates the tokens in the corpus file underlying this corpus view starting at the token number
:return the given file s as a list of words and punctuation symbols
initialize this object's probability this initializer should
:return the given file s as a list of sentences each encoded as a list of word tag tuples
:return a string representation of this canvas widget
work out the range of the mapping from the given positions
returns the arff data section for the given data
create a regexpchunkrule from a string description
abbc = asterisks breaks bold center
save the pickled model weights
a function variable must be a single uppercase character followed by zero or more digits
return a sequence of pos-tagged words extracted from the tree
:param goal input expression to prove :type goal sem
unify fstruct1 with fstruct2, and return the resulting feature structure
performs a projective dependency parse on the list of tokens using a chart-based span-concatenation algorithm similar to eisner 1996
:return the given file s as a list of sentences each encoded as a list of word tag tuples
return the unicode encoding for the given corpus file if known
return true iff 'self' subsumes 'other', this is if there is a substitution such that every term in 'self' can be unified with a term
demonstration code for evaluating a chunk parser using a chunkscore
construct a new probabilisticproduction
return a concise string representation of the production
returns the likelihood a float of the token having the corresponding cluster
train on sentence_aligned_corpus and create a lexical translation model a distortion model a fertility model and a
sentences in the test suite are divided into two classes - grammatical (accept) and
return the frequency of a given sample the frequency of a
a demonstration showing how trees and trees can be used
populate a dictionary of unigram features reflecting the presence/absence in the document of each of the tokens in unigrams
return iso 639-3 code given internal crubadan code
expand an ne class name
return a string containing a pretty-printed representation of the given verbnet frame description
return a string representation for this corpus view that is similar to a list's representation but if it would be more
helper function used by read_tuple_value and read_set_value
:param function the function that should be applied to elements of lists
return a string representation for this corpus view that is similar to a list's representation but if it would be more
take a class with a caller method and return a callable decorator
apply each rule of this regexpchunkparser to chunkstr, in turn
query the rest api for tweets about nltk since yesterday and send the output to terminal
:return a list of all words defined in the cmudict lexicon
add new rows at the end of the table
defines equality modulo alphabetic variance if we are comparing
return the set of all nonterminals that the given nonterminal can start with including itself
replace all instances of variable v with expression e in self where v is free in self
build the internal indexes to make look-ups faster
add a new variable-value pair to the assignment and update self
:return an value indexing the head of the entire dependencyspan
:return hypothesis with the highest score in the stack
:return a list of the utterance identifiers for all utterances in this corpus or for the given speaker dialect
:return the given file s as a single string
validate the set of rules used in this stemmer
helper function that returns an open file object for a resource given its resource url
for oauth 2 retrieve an access token for an app and append it to a credentials file
return a string representation for this nonterminal
the difference between the upper and lower date limits depends on whether tweets are coming in an ascending date order (i
convert a set of pairs into an adjacency linked list encoding of a graph
this method exists to be overridden
substitute words in the string according to the specified reflections e
initialize the indexes _lemma_to_class, _wordnet_to_class, and _class_to_fileid by scanning
handle a button-press event - record the button press event in self
the name of the file within zipfile that this path pointer points to
set the level of tracing output that should be generated when parsing a text
lists frame element objects if 'name' is provided this is treated as
:return a probability distribution over labels for the given featureset
convert a valuation string into a valuation
find the next best rule this is done by repeatedly taking a
:return (set<variables>, set<events>, set<propositions>)
:return a new treeedge formed from the given production
hack to help people like the readers of http //stackoverflow
return a set of predicates constants not variables
load an information content file from the wordnet_ic corpus and return a dictionary
remove all tags (except arrow and sel) from the given line of the text widget used for editing the productions
load a sentence from a subcorpus of an lu from xml
returns the pointwise entropy over the possible states at each position in the chain given the observation sequence
:type root pathpointer or str
the type with its final period removed if it is marked as a sentence break
:return an iterator over the permutations of the input list
a tuple containing the tkinter listbox widgets used to
modify and return the proof string
return a synset for an ambiguous word in a context
returns 1 minus the cosine of the angle between vectors v and u this is equal to
:param goal input expression to prove :type goal sem
add an epytext @field to a given object's docstring
configure nltk's interface to the megam maxent optimization package
use the cross-validation estimate to create a probability distribution for the experiment used to generate
calculates and returns parameters for sentence boundary detection as derived from training
returns the top n ngrams when scored by the given function
return a string containing a pretty-printed version of this decision tree
the class labels used by this classifier
:param estimator scikit-learn classifier object
returns the source of the best incoming arc to the node with address node_index
tabulate the given samples from the frequency distribution cumulative displaying the most frequent sample first
callback used to resize a column of the table return true
deal appropriately with data returned by the twitter api
return a string representation for this corpus view that is similar to a list's representation but if it would be more
retrieve the path through the similarity matrix s starting at i j
given a list of reference values and a corresponding list of test probability distributions return the average log likelihood of
true if the underlying stream is closed
convert a list of userids into a variety of information about the users
:param boxer_drs_interpreter a class that converts from the abstractboxerdrs object hierarchy to a different object
builds a lambda function which looks up the macro name used
returns the names of the cluster at index
if a python string literal begins at the specified position in the given string then return a tuple (val end_position)
:return the meaning's source group id
classify a single instance applying the features that have already been stored in the sentimentanalyzer
use nltk's currently recommended named entity chunker to chunk the given list of tagged sentences each consisting of a list of tagged tokens
gets rid of all tags and newline characters from the given input
add a new edge to the chart and return true if this operation modified the chart
pad the document with the place holder according to the window_size
subtract count but keep only results with positive counts
:return the text contents of the given fileids as a single string
construct a new tagged corpus reader for a set of documents located at the given root directory
decide whether the given token is the first token in a sentence
:return the given file s as a list of tagged words and punctuation symbols encoded as tuples
example of a propositional model
float amount of reordering of source phrases
return the chart that is used by this parser
concatenates the two spans in whichever way possible this
annotated sentences matching the specified criteria
:return the canvas managed by this canvasframe
given a slice return the corresponding start stop bounds taking into account none indices and negative indices
calculate the score of expanding hypothesis with
helper function for pretty-printing a long string
:param text a list containing tokenized text :type text list str
return the right-hand side length of the longest grammar production
helper function for pretty-printing a sentence with its pos tags
calculate the "out-of-place" measure between
starts the hunpos-tag executable and establishes a connection with it
:param loader when called with no arguments returns the value to be stored
implements step 3 from "an algorithm for suffix stripping"
construct a brill tagger from a baseline tagger and a
construct a new regexpchunkparser
load the lexical unit info from an xml element in a frame's xml file
override counter __delitem__() to invalidate the cached n
:rtype bool :return true if the right hand side of a cfg production
return the right-hand side length of the shortest grammar production
returns a list of scored synonyms tuples of synonyms and scores for the current ngram
return the expression to which 'variable' is bound
smoothing method 5 the matched counts for similar values of n should be similar
:param positive_featuresets a list of featuresets that are known as positive examples (i
helper function for pretty-printing a list of exemplar sentences for a lexical unit
replace any feature structure that has a forward pointer with the target of its forward pointer to preserve reentrancy
identify the tokens using integer offsets (start_i end_i), where s[start_i end_i] is the corresponding token
set vacancy probabilities uniformly to
read up to size bytes decode them using this reader's encoding and return the resulting unicode string
returns an element tree structure corresponding to a toolbox data file parsed according to the chunk grammar
:see readingcommand to_fol()
construct a new confusion matrix from a list of reference values and a corresponding list of test values
parse a drs condition
a decorator used to mark functions as deprecated this will cause
returns the set of all nodes that are immediately after the given node
return true if this dependencygrammar contains a dependencyproduction mapping 'head' to 'mod'
:rtype iter tree :return an iterator of all parses that can be generated by
return an iterator of the tree structures that are associated with edge
list of list of start end tag) tuples
dot-product the features and current weights and return the best label
average weights from all iterations
get the topmost hypernyms of this synset in wordnet
the sense number of the predicate
calculate and return the md5 checksum for a given file
make sure that no sibling tree bbox's overlap
print out the string representation of the respective class
construct a new treeedge
fertility of word in position i of the source sentence
add hypothesis to the stack
call the prover9 binary with the given input
a module to find maltparser jar file and its dependencies
:return the ceiling of the average positions of the words in
add counts from two counters
:see readingcommand process_thread()
list the current assumptions
create a new corpus view based on a specified xml file
returns the number of clusters
replace the value of a row or a cell in this table with val
wraps function arguments if fileids not specified then function set nkjpcorpusreader paths
:return the number of rows in this table
:seealso nltk prob freqdist
note that the algorithm for right-arc is different for arc-standard and arc-eager
trains a probabilisticdependencygrammar based on the list of input dependencygraphs
:param goal input expression to prove :type goal sem
phrase extraction algorithm extracts all consistent phrase pairs from a word-aligned sentence pair
print the list of the current assumptions
return a tokenized copy of *text*, using nltk's recommended word tokenizer
return an application expression with 'predicate' as the predicate and 'signature' as the list of arguments
the configure callback this is called whenever the window is
return true if fstruct1 subsumes fstruct2 i e return
return the set of all nonterminals for which the given category is a left corner
:param items the items at the leaves of the dendrogram
initialize the corpus reader categorization arguments
:return list of (sent_index word_indices) tuples
generate all the subtrees of this tree optionally restricted to trees matching the filter function
:return a concise string representation of this regexpchunkparser
display the list of sentences in the current discourse
calculates the average of function results for each coder pair
replace all instances of variable v with expression e in self where v is free in self
:param loc load a pickled model at location
ending step word of length five
tags the sequence with the highest probability state sequence this
construct a new chunkstring that encodes the chunking of the text tagged_tokens
skolemize the expression and convert to conjunctive normal form cnf
write the given sequence to a temporary file as a pickle corpus and then return a picklecorpusview view for that
return the chunks which were included in the correct chunk structures but not in the guessed chunk
return a generator that will add edges licensed by this rule and the given edges to the chart one at a time
:param name str for the constant name
delete all rows in this table
apply self classify() to each element of featuresets i e :
return the chunks which were included in the correct chunk structures listed in input order
return the size of the file pointed to by this path pointer in bytes
draw everything from scratch
stem a danish word and return the stemmed form
:return the given file s as a list of alignedsent objects
convert a file of first order formulas into a list of {expression}s
score the accuracy of the tagger against the gold standard
train on sentence_aligned_corpus and create a lexical translation model and an alignment model
configure this widget use label_* to configure all
based on the node return a list of plausible semtypes in order of plausibility
true if the token's first character is lowercase
remove this canvaswidget from its canvas after a
one left token and one right token normalized to lowercase
return a list of file identifiers for the files that make up this corpus or that make up the given category s if specified
replace every instance of 'variable' with 'expression'
self is a tautology if it contains ground terms p and -p the ground
change the grammar used to parse texts
find instances of the regular expression in the text
calculates values of contingency table marginals from its values
position this table's main frame widget in its parent widget
apply all feature extractor functions to the documents this is a wrapper
direct keyboard input foxus to this widget
wu-palmer similarity return a score denoting how similar two word senses are based on the
this method is intended to be overridden for logics that
:param context_to_tag a dictionary mapping contexts to tags
construct a map that can be used to compress nf which is typically sparse
write 20 tweets sampled from the public streaming api to a file
the url for the data server's index file
return true if self and other assign the same value to to every feature
returns an arff header as a string
determines whether or not the given ngram is in the thesaurus
return a randomly selected sample from this probability distribution
train on sentence_aligned_corpus and create a lexical translation model distortion models a fertility model and a
pop the first expression that appears in the agenda
use morphy from wordnet to find the base form of verbs
return the treesegmentwidget for the specified subtree
:see multilistbox rowconfigure()
return a list of the conditions that have been accessed for this conditionalfreqdist
return true if the given location is within the buffer
returns mapping of form
show a hidden canvas widget
return the frequency distribution that this probability distribution is based on
transform the output file into an nltk-style valuation
set the node label of the tree
:param depgraphs : list of dependencygraph as the training data
normalizes a resource url >>> windows = sys
remove a callback that was registered with bind_drag
add a new row to the end of the table
duck-typing the abstract *tokenize()*
return a list of s-expressions extracted from *text*
stem a romanian word and return the stemmed form
modify the list of items contained by this list
:return the list of category labels used by this classifier
return a tuple s e , where tokens[s e] is the portion of the sentence that is consistent with this
normalize short sufix
construct a new list
return the goal
return the node value corresponding to this nonterminal
compute the windowdiff score for a pair of segmentations a
set the level of tracing output that should be generated when parsing a text
a helper function for insert, which registers the new edge with all existing indexes
load a grammar from a pickle file
returns all of the words and punctuation symbols in the specified file that were in text nodes -- ie tags are ignored
train_text can either be the sole training text for this sentence boundary detector or can be a punktparameters object
computes the probability of a dependency graph based on the parser's probability model (defined by the parser's
draw the given item at the given location
appends the given span to the list of spans representing the chart cell's entries
return a vector with log probabilities of emitting a symbol when entering states
print the dendrogram in ascii art to standard out
replace any '->' text strings with arrows (char \256 in symbol font)
return a tokenized copy of *text*, where each "token" represents a separate topic
offset is represented as a number of 16khz samples!
creates a distribution of witten-bell probability estimates this
the backoff tagger for this tagger
demonstration of the module
a list of directories that should be searched for the prover9 executables
verify that the contents of the table's _rows variable match the contents of its multi-listbox (_mlb)
:return the meaning's id
perform the actual proof
:see abstractexpression get_refs()
:return whether the parser's current state represents a complete parse
:see multilistbox bind_to_listboxes()
:return the given file s as a list of words
flatten a list
:param fileids a list specifying the fileids that should be used
implements condition *d from the paper
create a new bottomupprobabilisticchartparser, that uses grammar to parse texts
assumes that the handler has been informed fetches tweets from
augment the lu information that was loaded from the frame file with additional information from the lu file
a helper function for insert, which registers the new edge with all existing indexes
save a chart to a pickle file
this method should be used to handle dependencies between readings such as resolving anaphora
splits a resource url into "<protocol>:<path>"
creates a new non-projective parser
defines equality modulo alphabetic variance
divide a string of bracketted tagged text into chunks and unchunked tokens and produce a tree
update the scroll-regions for each canvas this ensures that
construct a new slice from a given underlying sequence the
test that parsing works ok
:see multilistbox bind_to_columns()
check if the preceding words increase decrease or negate/nullify the
train and test naive bayes classifier on 10000 tweets tokenized using tweettokenizer
:param root the root directory for the corpus
collect information about whether each token type occurs with different case patterns i overall ii at
- domain = union([e free()|e constants() for e in all_expressions])
:param fileids a list specifying the fileids that should be used
arrange this canvas widget and all of its descendants
construct a new mergerule
destroy this canvasframe if this canvasframe created a
return a flat version of the tree with all non-root non-terminals removed
construct a new feature encoding based on the given function
applies the specified operation s on a list of tokens
:param labeled_featuresets a list of classified featuresets i
path distance similarity return a score denoting how similar two word senses are based on the
move a token from the beginning of the remaining text to the end of the stack
replace repeated character sequences of length 3 or greater with sequences of length 3
generate a response to the user input
overall score of hypothesis after accounting for local and
remove highlighting from the given item or from every item if no item is given
example of a first-order model
averaged over all labelers
generate an input file for megam based on the given corpus of classified tokens
make this feature structure and any feature structures it contains immutable
stem a swedish word and return the stemmed form
show the current background assumptions
helper function that reads in a feature structure
actions when the tweet limit has been reached
return the element of this edge's right-hand side that immediately follows its dot
:param fileids a list or regexp specifying the fileids of the files that have to be returned as a raw string
:return the most appropriate set of labels for the given featureset
return the total number of sample outcomes that have been recorded by this freqdist
:param root the root directory for this corpus
this will initialize the parameters required for the various smoothing techniques the default values are set to the numbers used in the
if this canvaswidget has a drag callback then call it otherwise find the closest ancestor with a drag callback and
use the rest api to convert a userid to a screen name
return the overall precision for all texts that have been scored by this chunkscore
given a correctly chunked sentence score another chunked version of the same sentence
construct a new empty conditional frequency distribution in
if this feature structure is frozen return its hash value otherwise raise typeerror
:param initial_tagger the initial tagger
:return the height of this canvas widget's bounding box in its canvas's coordinate space
return the cumulative frequencies of the specified samples
enter the tkinter mainloop this function must be called if
the observed disagreement for the alpha coefficient
:return true if the rule would change the tag of
:see expression visit_structured()
returns the set of all nodes that are immediately before the given node
print trace output indicating that a given production has been applied at a given location
decide which tag should be used for the specified token and return that tag
set the level of tracing output that should be generated when parsing a text
return a string representation for this corpus view that is similar to a list's representation but if it would be more
inserts string into the trie
return lemma object that matches the name
apply extractor functions and their parameters to the present document
non-interactive demonstration of the clusterers with simple 2-d data
from iddo lev's phd dissertation p108-109
construct a new plaintext corpus reader for a set of documents located at the given root directory
leacock chodorow similarity return a score denoting how similar two word senses are based on the
temporarily hide this canvas widget
from iddo lev's phd dissertation p108-109
compute per-class probabilities for a batch of samples
:return a corpus view that acts as a list of strings one for each line in the predicate-argument annotation file
return a list of 3-tuples containing word tag iob-tag
a demonstration of the earley parsers
:see expression visit()
the left sibling of this tree or none if it has none
use stanfordparser to parse a sentence takes a sentence as a list of
return a string containing a pretty-printed representation of the given verbnet frame syntax
given a set of tokens augmented with markers for line-start and paragraph-start returns an iterator through those tokens with full
load a chart from a pickle file
add new assumptions to the assumption list
helper function for pretty-printing an fe relation
return true if this dependencygrammar contains a dependencyproduction mapping 'head' to 'mod'
return the contents of the corpus readme file
update _tag_positions to reflect the changes to tags that are made by *rule*
normalization used in pre-processing
:param lst the underlying list
strip affixes from the token and return the stem
returns the names of the clusters
train fit the scikit-learn estimator
this method serves as a hook for other logic parsers that
insert the given row or rows into the table at the given index
return the leaves of the tree
read oauth credentials from a text file
a tuple containing the tkinter label widgets used to
update the graphical display of this canvas widget and all of its ancestors in response to a change in one of this canvas
given the tuple representation of a tagged token return the corresponding string representation
:return the position of the previous word that is in the same
:return a list of canvas tags for all graphical elements managed by this canvas widget not including graphical
return a verbose string representation of the dependencygrammar
set the value for the feature with the given name or path to value
return a string containing a pretty-printed representation of the given verbnet class's subclasses
construct a new timit corpus reader in the given directory
recursive function to indent an elementtree _elementinterface
return true if all productions are lexicalised
similarity
similarity
similarity
similarity
similarity
prefix
prefix
prefix
prefix
prefix
entropy
entropy
entropy
entropy
entropy
source_blocks
source_blocks
source_blocks
source_blocks
source_blocks
senna
senna
senna
senna
senna
findall
findall
findall
findall
findall
calculate
calculate
calculate
calculate
calculate
aug
aug
aug
aug
aug
n_xx
n_xx
n_xx
n_xx
n_xx
tweet
tweet
tweet
tweet
tweet
pprint
pprint
pprint
pprint
pprint
mwe
mwe
mwe
mwe
mwe
preprocess
preprocess
preprocess
preprocess
preprocess
tree2semi
tree2semi
tree2semi
tree2semi
tree2semi
alpino
alpino
alpino
alpino
alpino
save_classifier
save_classifier
save_classifier
save_classifier
save_classifier
cut_mark
cut_mark
cut_mark
cut_mark
cut_mark
bernoulli
bernoulli
bernoulli
bernoulli
bernoulli
cmd
cmd
cmd
cmd
cmd
vector
vector
vector
vector
vector
typecheck
typecheck
typecheck
typecheck
typecheck
indices
indices
indices
indices
indices
read_node
read_node
read_node
read_node
read_node
numoutcomes
numoutcomes
numoutcomes
numoutcomes
numoutcomes
est_bytes
est_bytes
est_bytes
est_bytes
est_bytes
p_n
p_n
p_n
p_n
p_n
sizehint
sizehint
sizehint
sizehint
sizehint
brill
brill
brill
brill
brill
second
second
second
second
second
n
n
n
n
n
trace_chart_width
trace_chart_width
trace_chart_width
trace_chart_width
trace_chart_width
errors
errors
errors
errors
errors
hide
hide
hide
hide
hide
neg
neg
neg
neg
neg
consequent
consequent
consequent
consequent
consequent
above
above
above
above
above
ney
ney
ney
ney
ney
new
new
new
new
new
net
net
net
net
net
entropy_cutoff
entropy_cutoff
entropy_cutoff
entropy_cutoff
entropy_cutoff
clausify
clausify
clausify
clausify
clausify
metadata
metadata
metadata
metadata
metadata
widget
widget
widget
widget
widget
max_phrase_length
max_phrase_length
max_phrase_length
max_phrase_length
max_phrase_length
path
path
path
path
path
chink
chink
chink
chink
chink
chunked
chunked
chunked
chunked
chunked
items
items
items
items
items
k
k
k
k
k
drt
drt
drt
drt
drt
set2rel
set2rel
set2rel
set2rel
set2rel
dependencies
dependencies
dependencies
dependencies
dependencies
gzip_compress
gzip_compress
gzip_compress
gzip_compress
gzip_compress
tokseqs
tokseqs
tokseqs
tokseqs
tokseqs
lusubcorpus
lusubcorpus
lusubcorpus
lusubcorpus
lusubcorpus
mwappdbcorpus
mwappdbcorpus
mwappdbcorpus
mwappdbcorpus
mwappdbcorpus
divide
divide
divide
divide
divide
classification
classification
classification
classification
classification
nomfile
nomfile
nomfile
nomfile
nomfile
of2ss
of2ss
of2ss
of2ss
of2ss
serialize
serialize
serialize
serialize
serialize
replace
replace
replace
replace
replace
initialize
initialize
initialize
initialize
initialize
txt
txt
txt
txt
txt
unit
unit
unit
unit
unit
plot
plot
plot
plot
plot
nechunk
nechunk
nechunk
nechunk
nechunk
icfile
icfile
icfile
icfile
icfile
substitutions
substitutions
substitutions
substitutions
substitutions
call
call
call
call
call
tokenize
tokenize
tokenize
tokenize
tokenize
combinator
combinator
combinator
combinator
combinator
type
type
type
type
type
tell
tell
tell
tell
tell
parentChar
parentChar
parentChar
parentChar
parentChar
senseval
senseval
senseval
senseval
senseval
naive
naive
naive
naive
naive
training
training
training
training
training
phone
phone
phone
phone
phone
seekable
seekable
seekable
seekable
seekable
hole
hole
hole
hole
hole
aligned
aligned
aligned
aligned
aligned
abspaths
abspaths
abspaths
abspaths
abspaths
mtecorpus
mtecorpus
mtecorpus
mtecorpus
mtecorpus
join
join
join
join
join
room
room
room
room
room
input_words
input_words
input_words
input_words
input_words
ignorekeys
ignorekeys
ignorekeys
ignorekeys
ignorekeys
deprecated
deprecated
deprecated
deprecated
deprecated
tok_cls
tok_cls
tok_cls
tok_cls
tok_cls
unichars
unichars
unichars
unichars
unichars
root
root
root
root
root
keep
keep
keep
keep
keep
motion
motion
motion
motion
motion
end
end
end
end
end
verify
verify
verify
verify
verify
str1
str1
str1
str1
str1
xmlinfo
xmlinfo
xmlinfo
xmlinfo
xmlinfo
feature
feature
feature
feature
feature
discourse_ids
discourse_ids
discourse_ids
discourse_ids
discourse_ids
character_based
character_based
character_based
character_based
character_based
initial_means
initial_means
initial_means
initial_means
initial_means
if
if
if
if
if
config
config
config
config
config
classify
classify
classify
classify
classify
dialect
dialect
dialect
dialect
dialect
blanks
blanks
blanks
blanks
blanks
description
description
description
description
description
arcs
arcs
arcs
arcs
arcs
turing
turing
turing
turing
turing
after
after
after
after
after
visited_self
visited_self
visited_self
visited_self
visited_self
predicates
predicates
predicates
predicates
predicates
types
types
types
types
types
attempt
attempt
attempt
attempt
attempt
hypotheses
hypotheses
hypotheses
hypotheses
hypotheses
first
first
first
first
first
num_sents
num_sents
num_sents
num_sents
num_sents
hapaxes
hapaxes
hapaxes
hapaxes
hapaxes
vars
vars
vars
vars
vars
synonyms
synonyms
synonyms
synonyms
synonyms
joinChar
joinChar
joinChar
joinChar
joinChar
before
before
before
before
before
min_score
min_score
min_score
min_score
min_score
fit
fit
fit
fit
fit
n_io
n_io
n_io
n_io
n_io
_s
_s
_s
_s
_s
n_ii
n_ii
n_ii
n_ii
n_ii
imp
imp
imp
imp
imp
production
production
production
production
production
str2records
str2records
str2records
str2records
str2records
name_or_path
name_or_path
name_or_path
name_or_path
name_or_path
hidden
hidden
hidden
hidden
hidden
cls
cls
cls
cls
cls
propbank
propbank
propbank
propbank
propbank
descape
descape
descape
descape
descape
target_blocks
target_blocks
target_blocks
target_blocks
target_blocks
one
one
one
one
one
decorator
decorator
decorator
decorator
decorator
argument_indices
argument_indices
argument_indices
argument_indices
argument_indices
grammar
grammar
grammar
grammar
grammar
prob_dist
prob_dist
prob_dist
prob_dist
prob_dist
cmudict
cmudict
cmudict
cmudict
cmudict
pformat
pformat
pformat
pformat
pformat
debug
debug
debug
debug
debug
classifier
classifier
classifier
classifier
classifier
head_address
head_address
head_address
head_address
head_address
xs
xs
xs
xs
xs
extract
extract
extract
extract
extract
ribes
ribes
ribes
ribes
ribes
rv
rv
rv
rv
rv
replace_bound
replace_bound
replace_bound
replace_bound
replace_bound
content
content
content
content
content
re
re
re
re
re
multiply
multiply
multiply
multiply
multiply
reader
reader
reader
reader
reader
treeposition
treeposition
treeposition
treeposition
treeposition
frel
frel
frel
frel
frel
translation_option
translation_option
translation_option
translation_option
translation_option
free
free
free
free
free
standard
standard
standard
standard
standard
review_lines
review_lines
review_lines
review_lines
review_lines
estimate
estimate
estimate
estimate
estimate
fcfg
fcfg
fcfg
fcfg
fcfg
markov
markov
markov
markov
markov
md5
md5
md5
md5
md5
source_tag
source_tag
source_tag
source_tag
source_tag
r1
r1
r1
r1
r1
starts
starts
starts
starts
starts
node_index
node_index
node_index
node_index
node_index
filter
filter
filter
filter
filter
beam_size
beam_size
beam_size
beam_size
beam_size
iso
iso
iso
iso
iso
signature
signature
signature
signature
signature
rand
rand
rand
rand
rand
eventvar
eventvar
eventvar
eventvar
eventvar
features
features
features
features
features
assumptions
assumptions
assumptions
assumptions
assumptions
rank
rank
rank
rank
rank
n_iiix_tuple
n_iiix_tuple
n_iiix_tuple
n_iiix_tuple
n_iiix_tuple
assign_clusters
assign_clusters
assign_clusters
assign_clusters
assign_clusters
featstruct
featstruct
featstruct
featstruct
featstruct
wrapper
wrapper
wrapper
wrapper
wrapper
delparent
delparent
delparent
delparent
delparent
enumerate
enumerate
enumerate
enumerate
enumerate
neighborhood
neighborhood
neighborhood
neighborhood
neighborhood
ids_f
ids_f
ids_f
ids_f
ids_f
convert2val
convert2val
convert2val
convert2val
convert2val
inStr
inStr
inStr
inStr
inStr
top
top
top
top
top
tok
tok
tok
tok
tok
master
master
master
master
master
brevity
brevity
brevity
brevity
brevity
corpus
corpus
corpus
corpus
corpus
synset_relations
synset_relations
synset_relations
synset_relations
synset_relations
danish
danish
danish
danish
danish
collapse
collapse
collapse
collapse
collapse
tool
tool
tool
tool
tool
inputfilename
inputfilename
inputfilename
inputfilename
inputfilename
remaining_text
remaining_text
remaining_text
remaining_text
remaining_text
distance
distance
distance
distance
distance
subcorpus
subcorpus
subcorpus
subcorpus
subcorpus
depth_scores
depth_scores
depth_scores
depth_scores
depth_scores
target
target
target
target
target
expr
expr
expr
expr
expr
tree
tree
tree
tree
tree
bigrams
bigrams
bigrams
bigrams
bigrams
prover9
prover9
prover9
prover9
prover9
col_index
col_index
col_index
col_index
col_index
raw
raw
raw
raw
raw
strip_space
strip_space
strip_space
strip_space
strip_space
seek
seek
seek
seek
seek
list2sym
list2sym
list2sym
list2sym
list2sym
reentrance_ids
reentrance_ids
reentrance_ids
reentrance_ids
reentrance_ids
test_set
test_set
test_set
test_set
test_set
cyrillic
cyrillic
cyrillic
cyrillic
cyrillic
indexes
indexes
indexes
indexes
indexes
left_context_tag_pattern
left_context_tag_pattern
left_context_tag_pattern
left_context_tag_pattern
left_context_tag_pattern
fname
fname
fname
fname
fname
column_weights
column_weights
column_weights
column_weights
column_weights
metrics
metrics
metrics
metrics
metrics
simplify
simplify
simplify
simplify
simplify
megam
megam
megam
megam
megam
fulltextannotation
fulltextannotation
fulltextannotation
fulltextannotation
fulltextannotation
iterate
iterate
iterate
iterate
iterate
toktype
toktype
toktype
toktype
toktype
doc
doc
doc
doc
doc
tautology
tautology
tautology
tautology
tautology
m
m
m
m
m
abbrev
abbrev
abbrev
abbrev
abbrev
bracket
bracket
bracket
bracket
bracket
attested
attested
attested
attested
attested
section
section
section
section
section
dot
dot
dot
dot
dot
random
random
random
random
random
syntax
syntax
syntax
syntax
syntax
i_pegged
i_pegged
i_pegged
i_pegged
i_pegged
future_score_table
future_score_table
future_score_table
future_score_table
future_score_table
attempts
attempts
attempts
attempts
attempts
stepping
stepping
stepping
stepping
stepping
keywords
keywords
keywords
keywords
keywords
max_id
max_id
max_id
max_id
max_id
xmlcorpus
xmlcorpus
xmlcorpus
xmlcorpus
xmlcorpus
menu
menu
menu
menu
menu
num_mots
num_mots
num_mots
num_mots
num_mots
semantics
semantics
semantics
semantics
semantics
do
do
do
do
do
dg
dg
dg
dg
dg
label2
label2
label2
label2
label2
stop
stop
stop
stop
stop
negated
negated
negated
negated
negated
toolbox
toolbox
toolbox
toolbox
toolbox
model5counts
model5counts
model5counts
model5counts
model5counts
fields
fields
fields
fields
fields
release
release
release
release
release
fertility
fertility
fertility
fertility
fertility
bleu
bleu
bleu
bleu
bleu
reference
reference
reference
reference
reference
left_tag_pattern
left_tag_pattern
left_tag_pattern
left_tag_pattern
left_tag_pattern
w6
w6
w6
w6
w6
w5
w5
w5
w5
w5
num
num
num
num
num
w3
w3
w3
w3
w3
w2
w2
w2
w2
w2
w1
w1
w1
w1
w1
best
best
best
best
best
lancaster
lancaster
lancaster
lancaster
lancaster
draw_parses
draw_parses
draw_parses
draw_parses
draw_parses
paice
paice
paice
paice
paice
tree_class
tree_class
tree_class
tree_class
tree_class
future
future
future
future
future
hyp_len
hyp_len
hyp_len
hyp_len
hyp_len
hunpos
hunpos
hunpos
hunpos
hunpos
C
C
C
C
C
triples
triples
triples
triples
triples
tokensequences
tokensequences
tokensequences
tokensequences
tokensequences
extend
extend
extend
extend
extend
confusion
confusion
confusion
confusion
confusion
cut
cut
cut
cut
cut
visited
visited
visited
visited
visited
src_phrase_span
src_phrase_span
src_phrase_span
src_phrase_span
src_phrase_span
defstr
defstr
defstr
defstr
defstr
creds
creds
creds
creds
creds
desired_x
desired_x
desired_x
desired_x
desired_x
logic
logic
logic
logic
logic
unk
unk
unk
unk
unk
col
col
col
col
col
themroles
themroles
themroles
themroles
themroles
exemplars
exemplars
exemplars
exemplars
exemplars
loader
loader
loader
loader
loader
loaded
loaded
loaded
loaded
loaded
nonlexical
nonlexical
nonlexical
nonlexical
nonlexical
featuresets
featuresets
featuresets
featuresets
featuresets
extraction
extraction
extraction
extraction
extraction
logarithmic
logarithmic
logarithmic
logarithmic
logarithmic
nombank
nombank
nombank
nombank
nombank
expected
expected
expected
expected
expected
collections
collections
collections
collections
collections
step1c
step1c
step1c
step1c
step1c
step1a
step1a
step1a
step1a
step1a
pdist
pdist
pdist
pdist
pdist
families
families
families
families
families
numsamples
numsamples
numsamples
numsamples
numsamples
argument
argument
argument
argument
argument
soft_delimiter
soft_delimiter
soft_delimiter
soft_delimiter
soft_delimiter
child
child
child
child
child
has
has
has
has
has
feature_func
feature_func
feature_func
feature_func
feature_func
euclidean
euclidean
euclidean
euclidean
euclidean
applies
applies
applies
applies
applies
property
property
property
property
property
leaves
leaves
leaves
leaves
leaves
cons
cons
cons
cons
cons
cont
cont
cont
cont
cont
full_text
full_text
full_text
full_text
full_text
is
is
is
is
is
it
it
it
it
it
ii
ii
ii
ii
ii
conf
conf
conf
conf
conf
in
in
in
in
in
comparative
comparative
comparative
comparative
comparative
ic
ic
ic
ic
ic
id
id
id
id
id
lcs
lcs
lcs
lcs
lcs
descent
descent
descent
descent
descent
make
make
make
make
make
cumulative
cumulative
cumulative
cumulative
cumulative
split
split
split
split
split
templates
templates
templates
templates
templates
userids
userids
userids
userids
userids
skolemize
skolemize
skolemize
skolemize
skolemize
outputfilename
outputfilename
outputfilename
outputfilename
outputfilename
lang_vars
lang_vars
lang_vars
lang_vars
lang_vars
overt
overt
overt
overt
overt
name_pattern
name_pattern
name_pattern
name_pattern
name_pattern
cycle
cycle
cycle
cycle
cycle
collapsePOS
collapsePOS
collapsePOS
collapsePOS
collapsePOS
elimeq
elimeq
elimeq
elimeq
elimeq
gzip
gzip
gzip
gzip
gzip
left
left
left
left
left
learning
learning
learning
learning
learning
sentence
sentence
sentence
sentence
sentence
applyto
applyto
applyto
applyto
applyto
par_breaks
par_breaks
par_breaks
par_breaks
par_breaks
ignore_case
ignore_case
ignore_case
ignore_case
ignore_case
proof_string
proof_string
proof_string
proof_string
proof_string
identify
identify
identify
identify
identify
keepends
keepends
keepends
keepends
keepends
previous
previous
previous
previous
previous
seg2
seg2
seg2
seg2
seg2
instance
instance
instance
instance
instance
prev_tok
prev_tok
prev_tok
prev_tok
prev_tok
slices
slices
slices
slices
slices
step4
step4
step4
step4
step4
step3
step3
step3
step3
step3
step2
step2
step2
step2
step2
save
save
save
save
save
elt
elt
elt
elt
elt
nkjpcorpus
nkjpcorpus
nkjpcorpus
nkjpcorpus
nkjpcorpus
rng
rng
rng
rng
rng
possible
possible
possible
possible
possible
clusterer
clusterer
clusterer
clusterer
clusterer
boxer
boxer
boxer
boxer
boxer
unification
unification
unification
unification
unification
bbox
bbox
bbox
bbox
bbox
background
background
background
background
background
elt_handler
elt_handler
elt_handler
elt_handler
elt_handler
unique
unique
unique
unique
unique
lch
lch
lch
lch
lch
hypernyms
hypernyms
hypernyms
hypernyms
hypernyms
specific
specific
specific
specific
specific
informative
informative
informative
informative
informative
istree
istree
istree
istree
istree
framenet
framenet
framenet
framenet
framenet
fileid
fileid
fileid
fileid
fileid
right
right
right
right
right
itemconfigure
itemconfigure
itemconfigure
itemconfigure
itemconfigure
str2chunktree
str2chunktree
str2chunktree
str2chunktree
str2chunktree
productions
productions
productions
productions
productions
flatten
flatten
flatten
flatten
flatten
escape
escape
escape
escape
escape
li_lj_tuple
li_lj_tuple
li_lj_tuple
li_lj_tuple
li_lj_tuple
conll
conll
conll
conll
conll
cooper
cooper
cooper
cooper
cooper
for
for
for
for
for
fdist
fdist
fdist
fdist
fdist
cnf
cnf
cnf
cnf
cnf
word_fd
word_fd
word_fd
word_fd
word_fd
fol
fol
fol
fol
fol
defaultdict
defaultdict
defaultdict
defaultdict
defaultdict
core
core
core
core
core
ss2of
ss2of
ss2of
ss2of
ss2of
detokenizer
detokenizer
detokenizer
detokenizer
detokenizer
sparse
sparse
sparse
sparse
sparse
discount
discount
discount
discount
discount
binder
binder
binder
binder
binder
fileobj
fileobj
fileobj
fileobj
fileobj
plug
plug
plug
plug
plug
valence
valence
valence
valence
valence
obj
obj
obj
obj
obj
ensure
ensure
ensure
ensure
ensure
primitive
primitive
primitive
primitive
primitive
sexpr
sexpr
sexpr
sexpr
sexpr
iccorpus
iccorpus
iccorpus
iccorpus
iccorpus
pair
pair
pair
pair
pair
rel2reldict
rel2reldict
rel2reldict
rel2reldict
rel2reldict
wrap
wrap
wrap
wrap
wrap
subj
subj
subj
subj
subj
errt
errt
errt
errt
errt
rels
rels
rels
rels
rels
initial
initial
initial
initial
initial
transform
transform
transform
transform
transform
unirand
unirand
unirand
unirand
unirand
width
width
width
width
width
waw
waw
waw
waw
waw
ccglexicon
ccglexicon
ccglexicon
ccglexicon
ccglexicon
timestamped
timestamped
timestamped
timestamped
timestamped
head
head
head
head
head
form
form
form
form
form
epsilon
epsilon
epsilon
epsilon
epsilon
thesaurus
thesaurus
thesaurus
thesaurus
thesaurus
framelexunit
framelexunit
framelexunit
framelexunit
framelexunit
decoder
decoder
decoder
decoder
decoder
attr
attr
attr
attr
attr
inside
inside
inside
inside
inside
bounds
bounds
bounds
bounds
bounds
annotations
annotations
annotations
annotations
annotations
nonterm_parser
nonterm_parser
nonterm_parser
nonterm_parser
nonterm_parser
decorate
decorate
decorate
decorate
decorate
include_rts
include_rts
include_rts
include_rts
include_rts
classid
classid
classid
classid
classid
hillclimb
hillclimb
hillclimb
hillclimb
hillclimb
trie
trie
trie
trie
trie
model2
model2
model2
model2
model2
abstract
abstract
abstract
abstract
abstract
backoff
backoff
backoff
backoff
backoff
prover
prover
prover
prover
prover
guessed
guessed
guessed
guessed
guessed
timezone
timezone
timezone
timezone
timezone
proverCommand
proverCommand
proverCommand
proverCommand
proverCommand
check
check
check
check
check
textids
textids
textids
textids
textids
ni
ni
ni
ni
ni
descr
descr
descr
descr
descr
no
no
no
no
no
ne
ne
ne
ne
ne
nx
nx
nx
nx
nx
reading_command
reading_command
reading_command
reading_command
reading_command
test
test
test
test
test
nr
nr
nr
nr
nr
scored
scored
scored
scored
scored
truncate
truncate
truncate
truncate
truncate
jaccard
jaccard
jaccard
jaccard
jaccard
models
models
models
models
models
comment_char
comment_char
comment_char
comment_char
comment_char
update
update
update
update
update
scorer
scorer
scorer
scorer
scorer
tagged_sentence
tagged_sentence
tagged_sentence
tagged_sentence
tagged_sentence
variable
variable
variable
variable
variable
column_names
column_names
column_names
column_names
column_names
regexp
regexp
regexp
regexp
regexp
bottom
bottom
bottom
bottom
bottom
feAbbrevs
feAbbrevs
feAbbrevs
feAbbrevs
feAbbrevs
maxdepth
maxdepth
maxdepth
maxdepth
maxdepth
time
time
time
time
time
push
push
push
push
push
resource_url
resource_url
resource_url
resource_url
resource_url
backward
backward
backward
backward
backward
breadth
breadth
breadth
breadth
breadth
concept
concept
concept
concept
concept
iterator
iterator
iterator
iterator
iterator
skip
skip
skip
skip
skip
chartrule
chartrule
chartrule
chartrule
chartrule
focus
focus
focus
focus
focus
trigram
trigram
trigram
trigram
trigram
devset
devset
devset
devset
devset
chunk_types
chunk_types
chunk_types
chunk_types
chunk_types
row
row
row
row
row
chunkstruct
chunkstruct
chunkstruct
chunkstruct
chunkstruct
bin_dir
bin_dir
bin_dir
bin_dir
bin_dir
sql
sql
sql
sql
sql
graph
graph
graph
graph
graph
indivs
indivs
indivs
indivs
indivs
nltkdemo18plus
nltkdemo18plus
nltkdemo18plus
nltkdemo18plus
nltkdemo18plus
unlabeled_sequences
unlabeled_sequences
unlabeled_sequences
unlabeled_sequences
unlabeled_sequences
text
text
text
text
text
accented
accented
accented
accented
accented
fstruct2
fstruct2
fstruct2
fstruct2
fstruct2
fstruct1
fstruct1
fstruct1
fstruct1
fstruct1
predicate
predicate
predicate
predicate
predicate
string
string
string
string
string
probdist_dict
probdist_dict
probdist_dict
probdist_dict
probdist_dict
seg1
seg1
seg1
seg1
seg1
svd_dimensions
svd_dimensions
svd_dimensions
svd_dimensions
svd_dimensions
choice
choice
choice
choice
choice
entries
entries
entries
entries
entries
word
word
word
word
word
level
level
level
level
level
iter
iter
iter
iter
iter
prob
prob
prob
prob
prob
tagged_tokens
tagged_tokens
tagged_tokens
tagged_tokens
tagged_tokens
item
item
item
item
item
setitem
setitem
setitem
setitem
setitem
quick
quick
quick
quick
quick
path_to_jar
path_to_jar
path_to_jar
path_to_jar
path_to_jar
dir
dir
dir
dir
dir
upper
upper
upper
upper
upper
leaf_labels
leaf_labels
leaf_labels
leaf_labels
leaf_labels
sent_type
sent_type
sent_type
sent_type
sent_type
max_len
max_len
max_len
max_len
max_len
n_instances
n_instances
n_instances
n_instances
n_instances
fn_fid
fn_fid
fn_fid
fn_fid
fn_fid
port
port
port
port
port
substitute
substitute
substitute
substitute
substitute
json2csv
json2csv
json2csv
json2csv
json2csv
replacement_tag
replacement_tag
replacement_tag
replacement_tag
replacement_tag
uniform
uniform
uniform
uniform
uniform
current
current
current
current
current
sequential
sequential
sequential
sequential
sequential
template
template
template
template
template
downloader
downloader
downloader
downloader
downloader
concepts
concepts
concepts
concepts
concepts
french
french
french
french
french
groups
groups
groups
groups
groups
address
address
address
address
address
langs
langs
langs
langs
langs
upper_date_limit
upper_date_limit
upper_date_limit
upper_date_limit
upper_date_limit
box
box
box
box
box
incoming
incoming
incoming
incoming
incoming
used_variables
used_variables
used_variables
used_variables
used_variables
shift
shift
shift
shift
shift
vectors
vectors
vectors
vectors
vectors
queue
queue
queue
queue
queue
delimiter
delimiter
delimiter
delimiter
delimiter
poisson
poisson
poisson
poisson
poisson
childChar
childChar
childChar
childChar
childChar
inference
inference
inference
inference
inference
cycle_path
cycle_path
cycle_path
cycle_path
cycle_path
rowvalues
rowvalues
rowvalues
rowvalues
rowvalues
dtype
dtype
dtype
dtype
dtype
rtefeature
rtefeature
rtefeature
rtefeature
rtefeature
linecolor
linecolor
linecolor
linecolor
linecolor
subjectivity
subjectivity
subjectivity
subjectivity
subjectivity
marker
marker
marker
marker
marker
cfgeditor
cfgeditor
cfgeditor
cfgeditor
cfgeditor
entities
entities
entities
entities
entities
pred
pred
pred
pred
pred
visit
visit
visit
visit
visit
modelBuilderCommand
modelBuilderCommand
modelBuilderCommand
modelBuilderCommand
modelBuilderCommand
handler
handler
handler
handler
handler
rowvalue
rowvalue
rowvalue
rowvalue
rowvalue
encode
encode
encode
encode
encode
train_sents
train_sents
train_sents
train_sents
train_sents
heldout_fdist
heldout_fdist
heldout_fdist
heldout_fdist
heldout_fdist
penn
penn
penn
penn
penn
outputs
outputs
outputs
outputs
outputs
output_format
output_format
output_format
output_format
output_format
rule_tuple
rule_tuple
rule_tuple
rule_tuple
rule_tuple
sfm_file
sfm_file
sfm_file
sfm_file
sfm_file
everywhere
everywhere
everywhere
everywhere
everywhere
iteredges
iteredges
iteredges
iteredges
iteredges
alpha_convert
alpha_convert
alpha_convert
alpha_convert
alpha_convert
local
local
local
local
local
modified
modified
modified
modified
modified
cat
cat
cat
cat
cat
reviews
reviews
reviews
reviews
reviews
labeled
labeled
labeled
labeled
labeled
regions
regions
regions
regions
regions
values
values
values
values
values
can
can
can
can
can
pickle
pickle
pickle
pickle
pickle
stream
stream
stream
stream
stream
predict
predict
predict
predict
predict
sample
sample
sample
sample
sample
drawer
drawer
drawer
drawer
drawer
incremental
incremental
incremental
incremental
incremental
handle
handle
handle
handle
handle
spanning
spanning
spanning
spanning
spanning
normalize
normalize
normalize
normalize
normalize
write
write
write
write
write
zipfilename
zipfilename
zipfilename
zipfilename
zipfilename
trigrams
trigrams
trigrams
trigrams
trigrams
ibmmodel
ibmmodel
ibmmodel
ibmmodel
ibmmodel
lower_date_limit
lower_date_limit
lower_date_limit
lower_date_limit
lower_date_limit
map
map
map
map
map
src_phrase
src_phrase
src_phrase
src_phrase
src_phrase
max
max
max
max
max
featureset
featureset
featureset
featureset
featureset
tagged_token
tagged_token
tagged_token
tagged_token
tagged_token
date
date
date
date
date
data
data
data
data
data
annotation
annotation
annotation
annotation
annotation
goal
goal
goal
goal
goal
ss
ss
ss
ss
ss
fromstring
fromstring
fromstring
fromstring
fromstring
sq
sq
sq
sq
sq
sp
sp
sp
sp
sp
timeout
timeout
timeout
timeout
timeout
st
st
st
st
st
q
q
q
q
q
rtecorpus
rtecorpus
rtecorpus
rtecorpus
rtecorpus
str2
str2
str2
str2
str2
skolem
skolem
skolem
skolem
skolem
extractor
extractor
extractor
extractor
extractor
tagged
tagged
tagged
tagged
tagged
constituents
constituents
constituents
constituents
constituents
fulltextindex
fulltextindex
fulltextindex
fulltextindex
fulltextindex
cols
cols
cols
cols
cols
getfileids
getfileids
getfileids
getfileids
getfileids
entity
entity
entity
entity
entity
lst
lst
lst
lst
lst
notrace
notrace
notrace
notrace
notrace
tagger
tagger
tagger
tagger
tagger
pointer
pointer
pointer
pointer
pointer
equiv
equiv
equiv
equiv
equiv
group
group
group
group
group
swadesh
swadesh
swadesh
swadesh
swadesh
treeseg
treeseg
treeseg
treeseg
treeseg
coordinates
coordinates
coordinates
coordinates
coordinates
forms
forms
forms
forms
forms
window
window
window
window
window
tweets
tweets
tweets
tweets
tweets
feats
feats
feats
feats
feats
non
non
non
non
non
views
views
views
views
views
score_fn
score_fn
score_fn
score_fn
score_fn
term
term
term
term
term
searchpath
searchpath
searchpath
searchpath
searchpath
equality
equality
equality
equality
equality
name
name
name
name
name
arrows
arrows
arrows
arrows
arrows
right_tag_pattern
right_tag_pattern
right_tag_pattern
right_tag_pattern
right_tag_pattern
lusentence
lusentence
lusentence
lusentence
lusentence
getitem
getitem
getitem
getitem
getitem
retrieve
retrieve
retrieve
retrieve
retrieve
newvar
newvar
newvar
newvar
newvar
sort_by_count
sort_by_count
sort_by_count
sort_by_count
sort_by_count
gaps
gaps
gaps
gaps
gaps
ex
ex
ex
ex
ex
transclose
transclose
transclose
transclose
transclose
eq
eq
eq
eq
eq
canvas
canvas
canvas
canvas
canvas
container
container
container
container
container
space
space
space
space
space
unlabeled_featuresets
unlabeled_featuresets
unlabeled_featuresets
unlabeled_featuresets
unlabeled_featuresets
factory
factory
factory
factory
factory
twitterclass
twitterclass
twitterclass
twitterclass
twitterclass
pad_right
pad_right
pad_right
pad_right
pad_right
dutch
dutch
dutch
dutch
dutch
formula
formula
formula
formula
formula
parser_dirname
parser_dirname
parser_dirname
parser_dirname
parser_dirname
correct
correct
correct
correct
correct
trglen
trglen
trglen
trglen
trglen
punkt
punkt
punkt
punkt
punkt
args
args
args
args
args
runBrowser
runBrowser
runBrowser
runBrowser
runBrowser
g
g
g
g
g
statistics
statistics
statistics
statistics
statistics
bayes
bayes
bayes
bayes
bayes
fecoreset
fecoreset
fecoreset
fecoreset
fecoreset
nonterminal
nonterminal
nonterminal
nonterminal
nonterminal
freqdist
freqdist
freqdist
freqdist
freqdist
punc
punc
punc
punc
punc
language
language
language
language
language
transition
transition
transition
transition
transition
quadgram
quadgram
quadgram
quadgram
quadgram
separator
separator
separator
separator
separator
safeappend
safeappend
safeappend
safeappend
safeappend
model_builder
model_builder
model_builder
model_builder
model_builder
lambda
lambda
lambda
lambda
lambda
clause
clause
clause
clause
clause
variables
variables
variables
variables
variables
tagdata
tagdata
tagdata
tagdata
tagdata
winlens
winlens
winlens
winlens
winlens
spanish
spanish
spanish
spanish
spanish
srclen
srclen
srclen
srclen
srclen
message
message
message
message
message
open
open
open
open
open
lemmawords
lemmawords
lemmawords
lemmawords
lemmawords
size
size
size
size
size
given
given
given
given
given
fmt
fmt
fmt
fmt
fmt
structured
structured
structured
structured
structured
2
2
2
2
2
params
params
params
params
params
constants
constants
constants
constants
constants
pos_tag
pos_tag
pos_tag
pos_tag
pos_tag
senti
senti
senti
senti
senti
leftcorner
leftcorner
leftcorner
leftcorner
leftcorner
credsfromfile
credsfromfile
credsfromfile
credsfromfile
credsfromfile
arity
arity
arity
arity
arity
sents
sents
sents
sents
sents
copy
copy
copy
copy
copy
png
png
png
png
png
analyze
analyze
analyze
analyze
analyze
utteranceids
utteranceids
utteranceids
utteranceids
utteranceids
r
r
r
r
r
prover9parent
prover9parent
prover9parent
prover9parent
prover9parent
and
and
and
and
and
pro
pro
pro
pro
pro
save_config
save_config
save_config
save_config
save_config
locations
locations
locations
locations
locations
general
general
general
general
general
transcription
transcription
transcription
transcription
transcription
repptokenizer
repptokenizer
repptokenizer
repptokenizer
repptokenizer
restr_keys
restr_keys
restr_keys
restr_keys
restr_keys
potential
potential
potential
potential
potential
destroy
destroy
destroy
destroy
destroy
nfmap
nfmap
nfmap
nfmap
nfmap
funccolor
funccolor
funccolor
funccolor
funccolor
printer
printer
printer
printer
printer
trace
trace
trace
trace
trace
normal
normal
normal
normal
normal
track
track
track
track
track
beta
beta
beta
beta
beta
reducible
reducible
reducible
reducible
reducible
evaluator
evaluator
evaluator
evaluator
evaluator
latex
latex
latex
latex
latex
fail_on_unknown
fail_on_unknown
fail_on_unknown
fail_on_unknown
fail_on_unknown
potential_labels0
potential_labels0
potential_labels0
potential_labels0
potential_labels0
average
average
average
average
average
order
order
order
order
order
chunkstr
chunkstr
chunkstr
chunkstr
chunkstr
mro
mro
mro
mro
mro
Trained
Trained
Trained
Trained
Trained
weight_senses_equally
weight_senses_equally
weight_senses_equally
weight_senses_equally
weight_senses_equally
sigma
sigma
sigma
sigma
sigma
review
review
review
review
review
lexicon
lexicon
lexicon
lexicon
lexicon
show
show
show
show
show
german
german
german
german
german
context_to_tag
context_to_tag
context_to_tag
context_to_tag
context_to_tag
wup
wup
wup
wup
wup
threshold
threshold
threshold
threshold
threshold
positive_featuresets
positive_featuresets
positive_featuresets
positive_featuresets
positive_featuresets
xml
xml
xml
xml
xml
ratio
ratio
ratio
ratio
ratio
dice
dice
dice
dice
dice
title
title
title
title
title
romanian
romanian
romanian
romanian
romanian
train_cls
train_cls
train_cls
train_cls
train_cls
dict
dict
dict
dict
dict
sentnum
sentnum
sentnum
sentnum
sentnum
logic_parser
logic_parser
logic_parser
logic_parser
logic_parser
omw_reader
omw_reader
omw_reader
omw_reader
omw_reader
hungarian
hungarian
hungarian
hungarian
hungarian
get
get
get
get
get
zipfile
zipfile
zipfile
zipfile
zipfile
repr
repr
repr
repr
repr
repp
repp
repp
repp
repp
templateid
templateid
templateid
templateid
templateid
print_parses
print_parses
print_parses
print_parses
print_parses
sentence_length
sentence_length
sentence_length
sentence_length
sentence_length
conjunction
conjunction
conjunction
conjunction
conjunction
closure
closure
closure
closure
closure
resource
resource
resource
resource
resource
settings
settings
settings
settings
settings
tag_pattern
tag_pattern
tag_pattern
tag_pattern
tag_pattern
nodedist
nodedist
nodedist
nodedist
nodedist
gaaclusterer
gaaclusterer
gaaclusterer
gaaclusterer
gaaclusterer
closures
closures
closures
closures
closures
relative
relative
relative
relative
relative
leftcorners
leftcorners
leftcorners
leftcorners
leftcorners
arff
arff
arff
arff
arff
verbnet
verbnet
verbnet
verbnet
verbnet
argument_pair
argument_pair
argument_pair
argument_pair
argument_pair
radd
radd
radd
radd
radd
n_ix_xi_tuple
n_ix_xi_tuple
n_ix_xi_tuple
n_ix_xi_tuple
n_ix_xi_tuple
taggedsents
taggedsents
taggedsents
taggedsents
taggedsents
lexical
lexical
lexical
lexical
lexical
label
label
label
label
label
boundaries
boundaries
boundaries
boundaries
boundaries
getattr
getattr
getattr
getattr
getattr
import
import
import
import
import
reading
reading
reading
reading
reading
parent
parent
parent
parent
parent
analyzer
analyzer
analyzer
analyzer
analyzer
treepositions
treepositions
treepositions
treepositions
treepositions
many
many
many
many
many
quiet
quiet
quiet
quiet
quiet
textwidget
textwidget
textwidget
textwidget
textwidget
s
s
s
s
s
sklearn
sklearn
sklearn
sklearn
sklearn
expression
expression
expression
expression
expression
cities2table
cities2table
cities2table
cities2table
cities2table
color
color
color
color
color
pos
pos
pos
pos
pos
pop
pop
pop
pop
pop
train_toks
train_toks
train_toks
train_toks
train_toks
subscr
subscr
subscr
subscr
subscr
iterations
iterations
iterations
iterations
iterations
index_by_id
index_by_id
index_by_id
index_by_id
index_by_id
rightmost_stack
rightmost_stack
rightmost_stack
rightmost_stack
rightmost_stack
aug_tok
aug_tok
aug_tok
aug_tok
aug_tok
invert
invert
invert
invert
invert
mark
mark
mark
mark
mark
_l
_l
_l
_l
_l
collocation
collocation
collocation
collocation
collocation
glueFormulaFactory
glueFormulaFactory
glueFormulaFactory
glueFormulaFactory
glueFormulaFactory
direction
direction
direction
direction
direction
binding_list
binding_list
binding_list
binding_list
binding_list
Tr
Tr
Tr
Tr
Tr
readings
readings
readings
readings
readings
intact_word
intact_word
intact_word
intact_word
intact_word
span1
span1
span1
span1
span1
span2
span2
span2
span2
span2
kappa
kappa
kappa
kappa
kappa
compile
compile
compile
compile
compile
europarl
europarl
europarl
europarl
europarl
conv_threshold
conv_threshold
conv_threshold
conv_threshold
conv_threshold
old_fn
old_fn
old_fn
old_fn
old_fn
stdout
stdout
stdout
stdout
stdout
concatenation
concatenation
concatenation
concatenation
concatenation
parse
parse
parse
parse
parse
cluster
cluster
cluster
cluster
cluster
visited_other
visited_other
visited_other
visited_other
visited_other
primitives
primitives
primitives
primitives
primitives
ascii
ascii
ascii
ascii
ascii
binary
binary
binary
binary
binary
pat
pat
pat
pat
pat
root_label
root_label
root_label
root_label
root_label
dry_run
dry_run
dry_run
dry_run
dry_run
renormalize
renormalize
renormalize
renormalize
renormalize
spkrid
spkrid
spkrid
spkrid
spkrid
html
html
html
html
html
pad
pad
pad
pad
pad
arguments
arguments
arguments
arguments
arguments
document
document
document
document
document
show_percents
show_percents
show_percents
show_percents
show_percents
status
status
status
status
status
support_cutoff
support_cutoff
support_cutoff
support_cutoff
support_cutoff
finish
finish
finish
finish
finish
closest
closest
closest
closest
closest
edges
edges
edges
edges
edges
pos_tuple
pos_tuple
pos_tuple
pos_tuple
pos_tuple
vowel
vowel
vowel
vowel
vowel
defn
defn
defn
defn
defn
threaded
threaded
threaded
threaded
threaded
macro
macro
macro
macro
macro
lemmatize
lemmatize
lemmatize
lemmatize
lemmatize
ccg
ccg
ccg
ccg
ccg
step5b
step5b
step5b
step5b
step5b
plug_acc
plug_acc
plug_acc
plug_acc
plug_acc
model_filename
model_filename
model_filename
model_filename
model_filename
unicode
unicode
unicode
unicode
unicode
max_models
max_models
max_models
max_models
max_models
streamtofile
streamtofile
streamtofile
streamtofile
streamtofile
heuristic
heuristic
heuristic
heuristic
heuristic
window_size
window_size
window_size
window_size
window_size
struct
struct
struct
struct
struct
paras
paras
paras
paras
paras
samples
samples
samples
samples
samples
rules
rules
rules
rules
rules
makeroom
makeroom
makeroom
makeroom
makeroom
period
period
period
period
period
postag
postag
postag
postag
postag
grid
grid
grid
grid
grid
world
world
world
world
world
mod
mod
mod
mod
mod
node_address
node_address
node_address
node_address
node_address
utterances
utterances
utterances
utterances
utterances
sanity
sanity
sanity
sanity
sanity
t
t
t
t
t
output
output
output
output
output
node
node
node
node
node
spans
spans
spans
spans
spans
synset_key
synset_key
synset_key
synset_key
synset_key
userid
userid
userid
userid
userid
conditional
conditional
conditional
conditional
conditional
draw
draw
draw
draw
draw
f_measure
f_measure
f_measure
f_measure
f_measure
slice
slice
slice
slice
slice
leafcolor
leafcolor
leafcolor
leafcolor
leafcolor
outf
outf
outf
outf
outf
porter
porter
porter
porter
porter
min_acc
min_acc
min_acc
min_acc
min_acc
classifier_builder
classifier_builder
classifier_builder
classifier_builder
classifier_builder
ngram
ngram
ngram
ngram
ngram
training_stats
training_stats
training_stats
training_stats
training_stats
elementtree
elementtree
elementtree
elementtree
elementtree
on
on
on
on
on
rmul
rmul
rmul
rmul
rmul
package
package
package
package
package
of
of
of
of
of
fringe
fringe
fringe
fringe
fringe
drag
drag
drag
drag
drag
srl
srl
srl
srl
srl
estimator
estimator
estimator
estimator
estimator
maltparser
maltparser
maltparser
maltparser
maltparser
or
or
or
or
or
lexunit
lexunit
lexunit
lexunit
lexunit
scores
scores
scores
scores
scores
treetok
treetok
treetok
treetok
treetok
annotate
annotate
annotate
annotate
annotate
thread_id
thread_id
thread_id
thread_id
thread_id
references
references
references
references
references
strip
strip
strip
strip
strip
Nr
Nr
Nr
Nr
Nr
semcor
semcor
semcor
semcor
semcor
b_graph
b_graph
b_graph
b_graph
b_graph
log
log
log
log
log
dispersion
dispersion
dispersion
dispersion
dispersion
strict
strict
strict
strict
strict
cosine
cosine
cosine
cosine
cosine
tagset
tagset
tagset
tagset
tagset
bubble
bubble
bubble
bubble
bubble
punctuation
punctuation
punctuation
punctuation
punctuation
lang
lang
lang
lang
lang
windowdiff
windowdiff
windowdiff
windowdiff
windowdiff
freqdists
freqdists
freqdists
freqdists
freqdists
complete
complete
complete
complete
complete
download_dir
download_dir
download_dir
download_dir
download_dir
printunused
printunused
printunused
printunused
printunused
devset_name
devset_name
devset_name
devset_name
devset_name
untag
untag
untag
untag
untag
unaryChar
unaryChar
unaryChar
unaryChar
unaryChar
stanford
stanford
stanford
stanford
stanford
default
default
default
default
default
exemplar
exemplar
exemplar
exemplar
exemplar
subclasses
subclasses
subclasses
subclasses
subclasses
pl196x
pl196x
pl196x
pl196x
pl196x
interval
interval
interval
interval
interval
citation
citation
citation
citation
citation
synset1
synset1
synset1
synset1
synset1
deep
deep
deep
deep
deep
synset2
synset2
synset2
synset2
synset2
unigrams
unigrams
unigrams
unigrams
unigrams
file
file
file
file
file
num_words
num_words
num_words
num_words
num_words
field
field
field
field
field
valid
valid
valid
valid
valid
input_file
input_file
input_file
input_file
input_file
symbol
symbol
symbol
symbol
symbol
taggedsent
taggedsent
taggedsent
taggedsent
taggedsent
synsets
synsets
synsets
synsets
synsets
dep_graph
dep_graph
dep_graph
dep_graph
dep_graph
ansi
ansi
ansi
ansi
ansi
row_index
row_index
row_index
row_index
row_index
coverage
coverage
coverage
coverage
coverage
concat
concat
concat
concat
concat
unbind
unbind
unbind
unbind
unbind
individual
individual
individual
individual
individual
curve
curve
curve
curve
curve
masi
masi
masi
masi
masi
mimic
mimic
mimic
mimic
mimic
u
u
u
u
u
fval1
fval1
fval1
fval1
fval1
fval2
fval2
fval2
fval2
fval2
resolution
resolution
resolution
resolution
resolution
strings
strings
strings
strings
strings
boxer_drs_interpreter
boxer_drs_interpreter
boxer_drs_interpreter
boxer_drs_interpreter
boxer_drs_interpreter
all
all
all
all
all
dependency_scorer
dependency_scorer
dependency_scorer
dependency_scorer
dependency_scorer
dist
dist
dist
dist
dist
pth
pth
pth
pth
pth
stems
stems
stems
stems
stems
luName
luName
luName
luName
luName
month
month
month
month
month
interpret
interpret
interpret
interpret
interpret
scalar
scalar
scalar
scalar
scalar
follow
follow
follow
follow
follow
expressions
expressions
expressions
expressions
expressions
token_cls
token_cls
token_cls
token_cls
token_cls
decisions
decisions
decisions
decisions
decisions
children
children
children
children
children
polarity
polarity
polarity
polarity
polarity
tr
tr
tr
tr
tr
ngrams
ngrams
ngrams
ngrams
ngrams
to
to
to
to
to
init
init
init
init
init
tf
tf
tf
tf
tf
nodes
nodes
nodes
nodes
nodes
immutable
immutable
immutable
immutable
immutable
norm
norm
norm
norm
norm
field_orders
field_orders
field_orders
field_orders
field_orders
translations
translations
translations
translations
translations
induce
induce
induce
induce
induce
witten
witten
witten
witten
witten
sentence_pair
sentence_pair
sentence_pair
sentence_pair
sentence_pair
condition
condition
condition
condition
condition
unigram
unigram
unigram
unigram
unigram
tagged_data
tagged_data
tagged_data
tagged_data
tagged_data
list
list
list
list
list
applicable
applicable
applicable
applicable
applicable
hyp
hyp
hyp
hyp
hyp
ngram2
ngram2
ngram2
ngram2
ngram2
ngram1
ngram1
ngram1
ngram1
ngram1
adjust
adjust
adjust
adjust
adjust
paragraph_breaks
paragraph_breaks
paragraph_breaks
paragraph_breaks
paragraph_breaks
dists
dists
dists
dists
dists
worder
worder
worder
worder
worder
unmark
unmark
unmark
unmark
unmark
propfile
propfile
propfile
propfile
propfile
rate
rate
rate
rate
rate
pass
pass
pass
pass
pass
check_reentrance
check_reentrance
check_reentrance
check_reentrance
check_reentrance
listbox
listbox
listbox
listbox
listbox
linear
linear
linear
linear
linear
subscripts
subscripts
subscripts
subscripts
subscripts
intersection
intersection
intersection
intersection
intersection
sub
sub
sub
sub
sub
brackets
brackets
brackets
brackets
brackets
diag
diag
diag
diag
diag
sum
sum
sum
sum
sum
offsets
offsets
offsets
offsets
offsets
mleprob
mleprob
mleprob
mleprob
mleprob
remove_total
remove_total
remove_total
remove_total
remove_total
method
method
method
method
method
positive_prob_prior
positive_prob_prior
positive_prob_prior
positive_prob_prior
positive_prob_prior
hash
hash
hash
hash
hash
tags
tags
tags
tags
tags
modify
modify
modify
modify
modify
threads
threads
threads
threads
threads
valuation_str
valuation_str
valuation_str
valuation_str
valuation_str
search
search
search
search
search
fstruct
fstruct
fstruct
fstruct
fstruct
buildindexes
buildindexes
buildindexes
buildindexes
buildindexes
labeled_featuresets
labeled_featuresets
labeled_featuresets
labeled_featuresets
labeled_featuresets
action
action
action
action
action
options
options
options
options
options
trainer
trainer
trainer
trainer
trainer
roleset_id
roleset_id
roleset_id
roleset_id
roleset_id
source_sents
source_sents
source_sents
source_sents
source_sents
verbose
verbose
verbose
verbose
verbose
tokenizer
tokenizer
tokenizer
tokenizer
tokenizer
filetype
filetype
filetype
filetype
filetype
tokenized
tokenized
tokenized
tokenized
tokenized
texts
texts
texts
texts
texts
framefiles
framefiles
framefiles
framefiles
framefiles
href
href
href
href
href
chunks
chunks
chunks
chunks
chunks
block_size
block_size
block_size
block_size
block_size
perceptron
perceptron
perceptron
perceptron
perceptron
freq
freq
freq
freq
freq
select
select
select
select
select
subsumes
subsumes
subsumes
subsumes
subsumes
probabilities
probabilities
probabilities
probabilities
probabilities
contains
contains
contains
contains
contains
vnclass
vnclass
vnclass
vnclass
vnclass
context_sentence
context_sentence
context_sentence
context_sentence
context_sentence
logprob
logprob
logprob
logprob
logprob
propdemo
propdemo
propdemo
propdemo
propdemo
fulltext
fulltext
fulltext
fulltext
fulltext
tester
tester
tester
tester
tester
abspath
abspath
abspath
abspath
abspath
flag
flag
flag
flag
flag
projective
projective
projective
projective
projective
min_freq
min_freq
min_freq
min_freq
min_freq
values_in_chart
values_in_chart
values_in_chart
values_in_chart
values_in_chart
dep
dep
dep
dep
dep
recall
recall
recall
recall
recall
malt
malt
malt
malt
malt
base_fdist
base_fdist
base_fdist
base_fdist
base_fdist
v
v
v
v
v
modelbuilder
modelbuilder
modelbuilder
modelbuilder
modelbuilder
dec
dec
dec
dec
dec
history
history
history
history
history
w53
w53
w53
w53
w53
w54
w54
w54
w54
w54
lex_str
lex_str
lex_str
lex_str
lex_str
minimum
minimum
minimum
minimum
minimum
phrase
phrase
phrase
phrase
phrase
framerelation
framerelation
framerelation
framerelation
framerelation
subtrees
subtrees
subtrees
subtrees
subtrees
recursive
recursive
recursive
recursive
recursive
listboxes
listboxes
listboxes
listboxes
listboxes
return_str
return_str
return_str
return_str
return_str
trg_phrase
trg_phrase
trg_phrase
trg_phrase
trg_phrase
e2f
e2f
e2f
e2f
e2f
stemming
stemming
stemming
stemming
stemming
frequencies
frequencies
frequencies
frequencies
frequencies
mutable
mutable
mutable
mutable
mutable
count_cutoff
count_cutoff
count_cutoff
count_cutoff
count_cutoff
mapping
mapping
mapping
mapping
mapping
smoothing_function
smoothing_function
smoothing_function
smoothing_function
smoothing_function
fe
fe
fe
fe
fe
reclassify
reclassify
reclassify
reclassify
reclassify
fn
fn
fn
fn
fn
a
a
a
a
a
nodecolor
nodecolor
nodecolor
nodecolor
nodecolor
register
register
register
register
register
callback
callback
callback
callback
callback
ortho
ortho
ortho
ortho
ortho
lhs
lhs
lhs
lhs
lhs
nltk
nltk
nltk
nltk
nltk
help
help
help
help
help
distortion
distortion
distortion
distortion
distortion
roots
roots
roots
roots
roots
style
style
style
style
style
forwards
forwards
forwards
forwards
forwards
speaker
speaker
speaker
speaker
speaker
cycle_indexes
cycle_indexes
cycle_indexes
cycle_indexes
cycle_indexes
good
good
good
good
good
lengthening
lengthening
lengthening
lengthening
lengthening
bracket_sent
bracket_sent
bracket_sent
bracket_sent
bracket_sent
verbsfile
verbsfile
verbsfile
verbsfile
verbsfile
bncword
bncword
bncword
bncword
bncword
token
token
token
token
token
gold_sents
gold_sents
gold_sents
gold_sents
gold_sents
wordnum
wordnum
wordnum
wordnum
wordnum
found
found
found
found
found
bigram
bigram
bigram
bigram
bigram
correctTag
correctTag
correctTag
correctTag
correctTag
defs
defs
defs
defs
defs
funcvar
funcvar
funcvar
funcvar
funcvar
reduce
reduce
reduce
reduce
reduce
connect
connect
connect
connect
connect
event
event
event
event
event
missed
missed
missed
missed
missed
p
p
p
p
p
print
print
print
print
print
top_n
top_n
top_n
top_n
top_n
token_table
token_table
token_table
token_table
token_table
base
base
base
base
base
cookie
cookie
cookie
cookie
cookie
proxy
proxy
proxy
proxy
proxy
backed
backed
backed
backed
backed
hard_delimiter
hard_delimiter
hard_delimiter
hard_delimiter
hard_delimiter
generate
generate
generate
generate
generate
pairs
pairs
pairs
pairs
pairs
thread
thread
thread
thread
thread
isristemmer
isristemmer
isristemmer
isristemmer
isristemmer
success
success
success
success
success
expecting
expecting
expecting
expecting
expecting
contingency
contingency
contingency
contingency
contingency
probability
probability
probability
probability
probability
encoding
encoding
encoding
encoding
encoding
save_analyzer
save_analyzer
save_analyzer
save_analyzer
save_analyzer
env_vars
env_vars
env_vars
env_vars
env_vars
misc
misc
misc
misc
misc
number
number
number
number
number
instances
instances
instances
instances
instances
stdlib
stdlib
stdlib
stdlib
stdlib
tree2conlltags
tree2conlltags
tree2conlltags
tree2conlltags
tree2conlltags
fileids
fileids
fileids
fileids
fileids
guess
guess
guess
guess
guess
tagdict
tagdict
tagdict
tagdict
tagdict
lidstone
lidstone
lidstone
lidstone
lidstone
construct
construct
construct
construct
construct
smoothed
smoothed
smoothed
smoothed
smoothed
store
store
store
store
store
option
option
option
option
option
min_len
min_len
min_len
min_len
min_len
depgraphs
depgraphs
depgraphs
depgraphs
depgraphs
alwayson_features
alwayson_features
alwayson_features
alwayson_features
alwayson_features
consonant
consonant
consonant
consonant
consonant
vocab
vocab
vocab
vocab
vocab
b
b
b
b
b
word_tokenizer
word_tokenizer
word_tokenizer
word_tokenizer
word_tokenizer
store_logs
store_logs
store_logs
store_logs
store_logs
scandinavian
scandinavian
scandinavian
scandinavian
scandinavian
pairwise
pairwise
pairwise
pairwise
pairwise
str
str
str
str
str
cept
cept
cept
cept
cept
wordfinder
wordfinder
wordfinder
wordfinder
wordfinder
categorized
categorized
categorized
categorized
categorized
sentences
sentences
sentences
sentences
sentences
chunk_struct
chunk_struct
chunk_struct
chunk_struct
chunk_struct
realign_boundaries
realign_boundaries
realign_boundaries
realign_boundaries
realign_boundaries
paths
paths
paths
paths
paths
retracted
retracted
retracted
retracted
retracted
conlltags2tree
conlltags2tree
conlltags2tree
conlltags2tree
conlltags2tree
lin
lin
lin
lin
lin
pmi
pmi
pmi
pmi
pmi
detokenize
detokenize
detokenize
detokenize
detokenize
build
build
build
build
build
probdist
probdist
probdist
probdist
probdist
warnings
warnings
warnings
warnings
warnings
rhs
rhs
rhs
rhs
rhs
measures
measures
measures
measures
measures
chart
chart
chart
chart
chart
most
most
most
most
most
mace
mace
mace
mace
mace
assoc
assoc
assoc
assoc
assoc
delitem
delitem
delitem
delitem
delitem
comparisons
comparisons
comparisons
comparisons
comparisons
alpha
alpha
alpha
alpha
alpha
probabilistic
probabilistic
probabilistic
probabilistic
probabilistic
model
model
model
model
model
aug_tok1
aug_tok1
aug_tok1
aug_tok1
aug_tok1
tokens
tokens
tokens
tokens
tokens
agressive_dash_splits
agressive_dash_splits
agressive_dash_splits
agressive_dash_splits
agressive_dash_splits
unsupervised
unsupervised
unsupervised
unsupervised
unsupervised
clear
clear
clear
clear
clear
crubadan
crubadan
crubadan
crubadan
crubadan
kw
kw
kw
kw
kw
reflections
reflections
reflections
reflections
reflections
exp
exp
exp
exp
exp
gold
gold
gold
gold
gold
unseen_features
unseen_features
unseen_features
unseen_features
unseen_features
vader
vader
vader
vader
vader
colorized
colorized
colorized
colorized
colorized
relation
relation
relation
relation
relation
find
find
find
find
find
access
access
access
access
access
parameters
parameters
parameters
parameters
parameters
train_text
train_text
train_text
train_text
train_text
writer
writer
writer
writer
writer
penalty
penalty
penalty
penalty
penalty
pretty
pretty
pretty
pretty
pretty
factor
factor
factor
factor
factor
moses
moses
moses
moses
moses
columns
columns
columns
columns
columns
dendrogram
dendrogram
dendrogram
dendrogram
dendrogram
training_set
training_set
training_set
training_set
training_set
pkg_xml
pkg_xml
pkg_xml
pkg_xml
pkg_xml
trees
trees
trees
trees
trees
chars
chars
chars
chars
chars
linenum
linenum
linenum
linenum
linenum
utcoffset
utcoffset
utcoffset
utcoffset
utcoffset
include_encoding
include_encoding
include_encoding
include_encoding
include_encoding
longest
longest
longest
longest
longest
depgraph
depgraph
depgraph
depgraph
depgraph
ibmmodel4
ibmmodel4
ibmmodel4
ibmmodel4
ibmmodel4
ibmmodel5
ibmmodel5
ibmmodel5
ibmmodel5
ibmmodel5
ibmmodel2
ibmmodel2
ibmmodel2
ibmmodel2
ibmmodel2
ibmmodel3
ibmmodel3
ibmmodel3
ibmmodel3
ibmmodel3
ibmmodel1
ibmmodel1
ibmmodel1
ibmmodel1
ibmmodel1
bytes
bytes
bytes
bytes
bytes
remove
remove
remove
remove
remove
tgrep
tgrep
tgrep
tgrep
tgrep
is_pos
is_pos
is_pos
is_pos
is_pos
double
double
double
double
double
x
x
x
x
x
set
set
set
set
set
seq
seq
seq
seq
seq
sep
sep
sep
sep
sep
creds_file
creds_file
creds_file
creds_file
creds_file
sex
sex
sex
sex
sex
see
see
see
see
see
arc
arc
arc
arc
arc
arg
arg
arg
arg
arg
close
close
close
close
close
sem
sem
sem
sem
sem
n_ixxx_tuple
n_ixxx_tuple
n_ixxx_tuple
n_ixxx_tuple
n_ixxx_tuple
sentbreak
sentbreak
sentbreak
sentbreak
sentbreak
multiposition
multiposition
multiposition
multiposition
multiposition
currently
currently
currently
currently
currently
binary_features
binary_features
binary_features
binary_features
binary_features
subdir
subdir
subdir
subdir
subdir
readme
readme
readme
readme
readme
formatter
formatter
formatter
formatter
formatter
conditions
conditions
conditions
conditions
conditions
concatenate
concatenate
concatenate
concatenate
concatenate
emclusterer
emclusterer
emclusterer
emclusterer
emclusterer
conds
conds
conds
conds
conds
sentperiod
sentperiod
sentperiod
sentperiod
sentperiod
outfile
outfile
outfile
outfile
outfile
to_screen
to_screen
to_screen
to_screen
to_screen
roleset
roleset
roleset
roleset
roleset
max_distance
max_distance
max_distance
max_distance
max_distance
findtype
findtype
findtype
findtype
findtype
n_oo
n_oo
n_oo
n_oo
n_oo
n_oi
n_oi
n_oi
n_oi
n_oi
c
c
c
c
c
f
f
f
f
f
last
last
last
last
last
license
license
license
license
license
maxent
maxent
maxent
maxent
maxent
roman
roman
roman
roman
roman
context
context
context
context
context
sent_tokenizer
sent_tokenizer
sent_tokenizer
sent_tokenizer
sent_tokenizer
load
load
load
load
load
markdown
markdown
markdown
markdown
markdown
bell
bell
bell
bell
bell
simple
simple
simple
simple
simple
header
header
header
header
header
slots
slots
slots
slots
slots
adaptively
adaptively
adaptively
adaptively
adaptively
pr
pr
pr
pr
pr
typed
typed
typed
typed
typed
java
java
java
java
java
create
create
create
create
create
slice_obj
slice_obj
slice_obj
slice_obj
slice_obj
strategy
strategy
strategy
strategy
strategy
ranks1
ranks1
ranks1
ranks1
ranks1
ranks2
ranks2
ranks2
ranks2
ranks2
pg
pg
pg
pg
pg
marginals
marginals
marginals
marginals
marginals
pi
pi
pi
pi
pi
empty
empty
empty
empty
empty
tgrep_string
tgrep_string
tgrep_string
tgrep_string
tgrep_string
setparent
setparent
setparent
setparent
setparent
precision
precision
precision
precision
precision
epytext
epytext
epytext
epytext
epytext
N
N
N
N
N
func
func
func
func
func
demand
demand
demand
demand
demand
mlb
mlb
mlb
mlb
mlb
unify
unify
unify
unify
unify
frozen
frozen
frozen
frozen
frozen
ferel
ferel
ferel
ferel
ferel
expanded
expanded
expanded
expanded
expanded
batch
batch
batch
batch
batch
error
error
error
error
error
fun
fun
fun
fun
fun
drs
drs
drs
drs
drs
heldout
heldout
heldout
heldout
heldout
value_string
value_string
value_string
value_string
value_string
loop
loop
loop
loop
loop
pack
pack
pack
pack
pack
index_counter
index_counter
index_counter
index_counter
index_counter
conllned
conllned
conllned
conllned
conllned
update_outputs
update_outputs
update_outputs
update_outputs
update_outputs
orthography
orthography
orthography
orthography
orthography
binding
binding
binding
binding
binding
tagspec
tagspec
tagspec
tagspec
tagspec
print_grammar
print_grammar
print_grammar
print_grammar
print_grammar
language_model
language_model
language_model
language_model
language_model
luNamePattern
luNamePattern
luNamePattern
luNamePattern
luNamePattern
current_states
current_states
current_states
current_states
current_states
result
result
result
result
result
emoticons
emoticons
emoticons
emoticons
emoticons
hexdigest
hexdigest
hexdigest
hexdigest
hexdigest
input_str
input_str
input_str
input_str
input_str
srctext
srctext
srctext
srctext
srctext
restrs
restrs
restrs
restrs
restrs
discourse
discourse
discourse
discourse
discourse
conflict
conflict
conflict
conflict
conflict
include_semantics
include_semantics
include_semantics
include_semantics
include_semantics
parented
parented
parented
parented
parented
keys
keys
keys
keys
keys
assignment
assignment
assignment
assignment
assignment
timit
timit
timit
timit
timit
yesterday
yesterday
yesterday
yesterday
yesterday
start_position
start_position
start_position
start_position
start_position
user
user
user
user
user
nouns
nouns
nouns
nouns
nouns
antecedents
antecedents
antecedents
antecedents
antecedents
stack
stack
stack
stack
stack
lower
lower
lower
lower
lower
task
task
task
task
task
elem
elem
elem
elem
elem
edge
edge
edge
edge
edge
y
y
y
y
y
entry
entry
entry
entry
entry
rowconfigure
rowconfigure
rowconfigure
rowconfigure
rowconfigure
distances
distances
distances
distances
distances
max_rules
max_rules
max_rules
max_rules
max_rules
db
db
db
db
db
debug_level
debug_level
debug_level
debug_level
debug_level
atomic
atomic
atomic
atomic
atomic
fntbl37
fntbl37
fntbl37
fntbl37
fntbl37
newvars
newvars
newvars
newvars
newvars
alignment
alignment
alignment
alignment
alignment
rtext
rtext
rtext
rtext
rtext
password
password
password
password
password
tablet
tablet
tablet
tablet
tablet
desired_y
desired_y
desired_y
desired_y
desired_y
frameID
frameID
frameID
frameID
frameID
source
source
source
source
source
parents
parents
parents
parents
parents
location
location
location
location
location
theorem
theorem
theorem
theorem
theorem
input
input
input
input
input
remaining
remaining
remaining
remaining
remaining
finder
finder
finder
finder
finder
bin
bin
bin
bin
bin
manage
manage
manage
manage
manage
finalize
finalize
finalize
finalize
finalize
format
format
format
format
format
evaluate
evaluate
evaluate
evaluate
evaluate
prover9command
prover9command
prover9command
prover9command
prover9command
bnccorpus
bnccorpus
bnccorpus
bnccorpus
bnccorpus
d
d
d
d
d
semi
semi
semi
semi
semi
ignore
ignore
ignore
ignore
ignore
collect
collect
collect
collect
collect
continue
continue
continue
continue
continue
alignments
alignments
alignments
alignments
alignments
training_opt
training_opt
training_opt
training_opt
training_opt
nertagger
nertagger
nertagger
nertagger
nertagger
eleprob
eleprob
eleprob
eleprob
eleprob
tuple2str
tuple2str
tuple2str
tuple2str
tuple2str
allow_step
allow_step
allow_step
allow_step
allow_step
multifeature
multifeature
multifeature
multifeature
multifeature
new_node
new_node
new_node
new_node
new_node
decision
decision
decision
decision
decision
pros
pros
pros
pros
pros
j_pegged
j_pegged
j_pegged
j_pegged
j_pegged
colortags
colortags
colortags
colortags
colortags
synset
synset
synset
synset
synset
ellipsis
ellipsis
ellipsis
ellipsis
ellipsis
leftmost
leftmost
leftmost
leftmost
leftmost
chunkparser
chunkparser
chunkparser
chunkparser
chunkparser
minimal
minimal
minimal
minimal
minimal
wordnetids
wordnetids
wordnetids
wordnetids
wordnetids
method4
method4
method4
method4
method4
method5
method5
method5
method5
method5
run
run
run
run
run
method3
method3
method3
method3
method3
method1
method1
method1
method1
method1
stem
stem
stem
stem
stem
step
step
step
step
step
count_ab
count_ab
count_ab
count_ab
count_ab
subtract
subtract
subtract
subtract
subtract
by
by
by
by
by
idx
idx
idx
idx
idx
chomsky
chomsky
chomsky
chomsky
chomsky
prove
prove
prove
prove
prove
fs_class
fs_class
fs_class
fs_class
fs_class
maxlen
maxlen
maxlen
maxlen
maxlen
range
range
range
range
range
positive
positive
positive
positive
positive
idf
idf
idf
idf
idf
webview
webview
webview
webview
webview
block
block
block
block
block
chunk_label
chunk_label
chunk_label
chunk_label
chunk_label
top_relation_label
top_relation_label
top_relation_label
top_relation_label
top_relation_label
tadm
tadm
tadm
tadm
tadm
discard_empty
discard_empty
discard_empty
discard_empty
discard_empty
frames
frames
frames
frames
frames
treeloc
treeloc
treeloc
treeloc
treeloc
rows
rows
rows
rows
rows
span
span
span
span
span
aug_tok2
aug_tok2
aug_tok2
aug_tok2
aug_tok2
question
question
question
question
question
custom
custom
custom
custom
custom
occupy
occupy
occupy
occupy
occupy
depth_cutoff
depth_cutoff
depth_cutoff
depth_cutoff
depth_cutoff
ycoecorpus
ycoecorpus
ycoecorpus
ycoecorpus
ycoecorpus
age_year
age_year
age_year
age_year
age_year
forward
forward
forward
forward
forward
translate
translate
translate
translate
translate
usr
usr
usr
usr
usr
wnb
wnb
wnb
wnb
wnb
tagged_corpus
tagged_corpus
tagged_corpus
tagged_corpus
tagged_corpus
delta
delta
delta
delta
delta
russian
russian
russian
russian
russian
frame2
frame2
frame2
frame2
frame2
line
line
line
line
line
info
info
info
info
info
utc
utc
utc
utc
utc
originals
originals
originals
originals
originals
source_sents_lens
source_sents_lens
source_sents_lens
source_sents_lens
source_sents_lens
caller
caller
caller
caller
caller
up
up
up
up
up
un
un
un
un
un
highlight
highlight
highlight
highlight
highlight
laplace
laplace
laplace
laplace
laplace
constant
constant
constant
constant
constant
all_phrases_from
all_phrases_from
all_phrases_from
all_phrases_from
all_phrases_from
parses
parses
parses
parses
parses
parser
parser
parser
parser
parser
readlines
readlines
readlines
readlines
readlines
char
char
char
char
char
treepos
treepos
treepos
treepos
treepos
chat
chat
chat
chat
chat
tiling
tiling
tiling
tiling
tiling
ancestors
ancestors
ancestors
ancestors
ancestors
mwes
mwes
mwes
mwes
mwes
priors
priors
priors
priors
priors
application
application
application
application
application
token_sequences
token_sequences
token_sequences
token_sequences
token_sequences
retract
retract
retract
retract
retract
gisencoding
gisencoding
gisencoding
gisencoding
gisencoding
is_cap_diff
is_cap_diff
is_cap_diff
is_cap_diff
is_cap_diff
aset
aset
aset
aset
aset
meaning
meaning
meaning
meaning
meaning
authenticate
authenticate
authenticate
authenticate
authenticate
eval
eval
eval
eval
eval
mwetokenizer
mwetokenizer
mwetokenizer
mwetokenizer
mwetokenizer
sensenumber
sensenumber
sensenumber
sensenumber
sensenumber
unlabeled_sequence
unlabeled_sequence
unlabeled_sequence
unlabeled_sequence
unlabeled_sequence
antecedent
antecedent
antecedent
antecedent
antecedent
e
e
e
e
e
svg
svg
svg
svg
svg
age
age
age
age
age
target_sents
target_sents
target_sents
target_sents
target_sents
depth
depth
depth
depth
depth
weights
weights
weights
weights
weights
scroll
scroll
scroll
scroll
scroll
partial
partial
partial
partial
partial
longstring
longstring
longstring
longstring
longstring
toggle
toggle
toggle
toggle
toggle
query
query
query
query
query
deterministic
deterministic
deterministic
deterministic
deterministic
base_url
base_url
base_url
base_url
base_url
starter
starter
starter
starter
starter
sent
sent
sent
sent
sent
labels
labels
labels
labels
labels
compresslevel
compresslevel
compresslevel
compresslevel
compresslevel
w64
w64
w64
w64
w64
dbname
dbname
dbname
dbname
dbname
categories
categories
categories
categories
categories
positions
positions
positions
positions
positions
button
button
button
button
button
reentrances
reentrances
reentrances
reentrances
reentrances
logfilename
logfilename
logfilename
logfilename
logfilename
default_fields
default_fields
default_fields
default_fields
default_fields
cfg
cfg
cfg
cfg
cfg
zf
zf
zf
zf
zf
download
download
download
download
download
textcolor
textcolor
textcolor
textcolor
textcolor
click
click
click
click
click
append
append
append
append
append
compat
compat
compat
compat
compat
index
index
index
index
index
target_word_classes
target_word_classes
target_word_classes
target_word_classes
target_word_classes
cell
cell
cell
cell
cell
ambiguous_word
ambiguous_word
ambiguous_word
ambiguous_word
ambiguous_word
pcfg
pcfg
pcfg
pcfg
pcfg
body
body
body
body
body
num_entities
num_entities
num_entities
num_entities
num_entities
len
len
len
len
len
punct
punct
punct
punct
punct
lex
lex
lex
lex
lex
skipgrams
skipgrams
skipgrams
skipgrams
skipgrams
opinion
opinion
opinion
opinion
opinion
buffered
buffered
buffered
buffered
buffered
app
app
app
app
app
offset
offset
offset
offset
offset
boolean
boolean
boolean
boolean
boolean
names
names
names
names
names
pre32
pre32
pre32
pre32
pre32
oval
oval
oval
oval
oval
apply
apply
apply
apply
apply
bindings
bindings
bindings
bindings
bindings
modelfile
modelfile
modelfile
modelfile
modelfile
use
use
use
use
use
from
from
from
from
from
zip
zip
zip
zip
zip
chi
chi
chi
chi
chi
next
next
next
next
next
fes
fes
fes
fes
fes
tab_file
tab_file
tab_file
tab_file
tab_file
canvaswidget
canvaswidget
canvaswidget
canvaswidget
canvaswidget
sort
sort
sort
sort
sort
iis
iis
iis
iis
iis
comparison
comparison
comparison
comparison
comparison
spkrinfo
spkrinfo
spkrinfo
spkrinfo
spkrinfo
stirling
stirling
stirling
stirling
stirling
train
train
train
train
train
iii
iii
iii
iii
iii
resize
resize
resize
resize
resize
screen_name
screen_name
screen_name
screen_name
screen_name
augment
augment
augment
augment
augment
fstruct_reader
fstruct_reader
fstruct_reader
fstruct_reader
fstruct_reader
univ_scope
univ_scope
univ_scope
univ_scope
univ_scope
averaged
averaged
averaged
averaged
averaged
tag
tag
tag
tag
tag
fe2
fe2
fe2
fe2
fe2
satdemo
satdemo
satdemo
satdemo
satdemo
proof
proof
proof
proof
proof
tau
tau
tau
tau
tau
process
process
process
process
process
test_sents
test_sents
test_sents
test_sents
test_sents
initial_tagger
initial_tagger
initial_tagger
initial_tagger
initial_tagger
streamer
streamer
streamer
streamer
streamer
expandable
expandable
expandable
expandable
expandable
tableau
tableau
tableau
tableau
tableau
chunk_tag_pattern
chunk_tag_pattern
chunk_tag_pattern
chunk_tag_pattern
chunk_tag_pattern
chrf
chrf
chrf
chrf
chrf
expandUnary
expandUnary
expandUnary
expandUnary
expandUnary
label1
label1
label1
label1
label1
pluggings
pluggings
pluggings
pluggings
pluggings
swedish
swedish
swedish
swedish
swedish
blocks
blocks
blocks
blocks
blocks
overridden
overridden
overridden
overridden
overridden
vowels
vowels
vowels
vowels
vowels
collection
collection
collection
collection
collection
bind
bind
bind
bind
bind
counter
counter
counter
counter
counter
lines
lines
lines
lines
lines
element
element
element
element
element
agenda
agenda
agenda
agenda
agenda
trigram_fd
trigram_fd
trigram_fd
trigram_fd
trigram_fd
bins
bins
bins
bins
bins
verify_tags
verify_tags
verify_tags
verify_tags
verify_tags
symbols
symbols
symbols
symbols
symbols
dt
dt
dt
dt
dt
join_char
join_char
join_char
join_char
join_char
orders_dicts
orders_dicts
orders_dicts
orders_dicts
orders_dicts
collocations
collocations
collocations
collocations
collocations
tempfile
tempfile
tempfile
tempfile
tempfile
folmodel
folmodel
folmodel
folmodel
folmodel
lu
lu
lu
lu
lu
choose
choose
choose
choose
choose
clusters
clusters
clusters
clusters
clusters
gleu
gleu
gleu
gleu
gleu
etree
etree
etree
etree
etree
stemmer
stemmer
stemmer
stemmer
stemmer
descendants
descendants
descendants
descendants
descendants
print_trees
print_trees
print_trees
print_trees
print_trees
docs
docs
docs
docs
docs
pad_left
pad_left
pad_left
pad_left
pad_left
ccgvar
ccgvar
ccgvar
ccgvar
ccgvar
toks
toks
toks
toks
toks
nextsym
nextsym
nextsym
nextsym
nextsym
rel_name
rel_name
rel_name
rel_name
rel_name
merge
merge
merge
merge
merge
l2
l2
l2
l2
l2
mode
mode
mode
mode
mode
truth
truth
truth
truth
truth
l1
l1
l1
l1
l1
column_index
column_index
column_index
column_index
column_index
hypernym
hypernym
hypernym
hypernym
hypernym
inputs
inputs
inputs
inputs
inputs
right_context_tag_pattern
right_context_tag_pattern
right_context_tag_pattern
right_context_tag_pattern
right_context_tag_pattern
chunk
chunk
chunk
chunk
chunk
n_iiii
n_iiii
n_iiii
n_iiii
n_iiii
negate
negate
negate
negate
negate
excludezero
excludezero
excludezero
excludezero
excludezero
static
static
static
static
static
measure
measure
measure
measure
measure
transitions
transitions
transitions
transitions
transitions
tabulate
tabulate
tabulate
tabulate
tabulate
category
category
category
category
category
matrix
matrix
matrix
matrix
matrix
sentiment
sentiment
sentiment
sentiment
sentiment
frontier
frontier
frontier
frontier
frontier
rel
rel
rel
rel
rel
ieerstr2tree
ieerstr2tree
ieerstr2tree
ieerstr2tree
ieerstr2tree
ref
ref
ref
ref
ref
common
common
common
common
common
dictionary
dictionary
dictionary
dictionary
dictionary
loc
loc
loc
loc
loc
raw_score
raw_score
raw_score
raw_score
raw_score
conflicts
conflicts
conflicts
conflicts
conflicts
likelihood
likelihood
likelihood
likelihood
likelihood
shortest
shortest
shortest
shortest
shortest
handle_negation
handle_negation
handle_negation
handle_negation
handle_negation
indent
indent
indent
indent
indent
path_to_bin
path_to_bin
path_to_bin
path_to_bin
path_to_bin
phrases
phrases
phrases
phrases
phrases
timer
timer
timer
timer
timer
times
times
times
times
times
length
length
length
length
length
prim_only
prim_only
prim_only
prim_only
prim_only
kendall
kendall
kendall
kendall
kendall
respond
respond
respond
respond
respond
reflexive
reflexive
reflexive
reflexive
reflexive
vectorspace
vectorspace
vectorspace
vectorspace
vectorspace
decode
decode
decode
decode
decode
dump
dump
dump
dump
dump
start
start
start
start
start
source_word_classes
source_word_classes
source_word_classes
source_word_classes
source_word_classes
system
system
system
system
system
relations
relations
relations
relations
relations
grow
grow
grow
grow
grow
crftagger
crftagger
crftagger
crftagger
crftagger
widgets
widgets
widgets
widgets
widgets
final
final
final
final
final
foldemo
foldemo
foldemo
foldemo
foldemo
configure
configure
configure
configure
configure
calculate_leftcorners
calculate_leftcorners
calculate_leftcorners
calculate_leftcorners
calculate_leftcorners
closest_ref_len
closest_ref_len
closest_ref_len
closest_ref_len
closest_ref_len
lists
lists
lists
lists
lists
nbest
nbest
nbest
nbest
nbest
prune
prune
prune
prune
prune
sentence_aligned_corpus
sentence_aligned_corpus
sentence_aligned_corpus
sentence_aligned_corpus
sentence_aligned_corpus
predid
predid
predid
predid
predid
subsequence
subsequence
subsequence
subsequence
subsequence
w4
w4
w4
w4
w4
lemmas
lemmas
lemmas
lemmas
lemmas
covariance_matrices
covariance_matrices
covariance_matrices
covariance_matrices
covariance_matrices
nonprojective
nonprojective
nonprojective
nonprojective
nonprojective
include_fileid
include_fileid
include_fileid
include_fileid
include_fileid
stdin
stdin
stdin
stdin
stdin
followtoscreen
followtoscreen
followtoscreen
followtoscreen
followtoscreen
plaintext
plaintext
plaintext
plaintext
plaintext
list_of_references
list_of_references
list_of_references
list_of_references
list_of_references
documents
documents
documents
documents
documents
mappings
mappings
mappings
mappings
mappings
min
min
min
min
min
bigram_fd
bigram_fd
bigram_fd
bigram_fd
bigram_fd
scrollregion
scrollregion
scrollregion
scrollregion
scrollregion
mix
mix
mix
mix
mix
read
read
read
read
read
tagword
tagword
tagword
tagword
tagword
detector
detector
detector
detector
detector
accuracy
accuracy
accuracy
accuracy
accuracy
info_or_id
info_or_id
info_or_id
info_or_id
info_or_id
json_file
json_file
json_file
json_file
json_file
fn_docid
fn_docid
fn_docid
fn_docid
fn_docid
plugging
plugging
plugging
plugging
plugging
tagstr2tree
tagstr2tree
tagstr2tree
tagstr2tree
tagstr2tree
propagate
propagate
propagate
propagate
propagate
plus
plus
plus
plus
plus
segment
segment
segment
segment
segment
class
class
class
class
class
append_string
append_string
append_string
append_string
append_string
url
url
url
url
url
neighboring
neighboring
neighboring
neighboring
neighboring
qtree
qtree
qtree
qtree
qtree
graphs
graphs
graphs
graphs
graphs
probability_tables
probability_tables
probability_tables
probability_tables
probability_tables
selection
selection
selection
selection
selection
mainloop
mainloop
mainloop
mainloop
mainloop
chapters
chapters
chapters
chapters
chapters
vacancy
vacancy
vacancy
vacancy
vacancy
filename
filename
filename
filename
filename
feat
feat
feat
feat
feat
redirect
redirect
redirect
redirect
redirect
based
based
based
based
based
trg_classes
trg_classes
trg_classes
trg_classes
trg_classes
with
with
with
with
with
cache
cache
cache
cache
cache
jar
jar
jar
jar
jar
terminal
terminal
terminal
terminal
terminal
lemma
lemma
lemma
lemma
lemma
score
score
score
score
score
status_code
status_code
status_code
status_code
status_code
nounsfile
nounsfile
nounsfile
nounsfile
nounsfile
abbc
abbc
abbc
abbc
abbc
means
means
means
means
means
convert
convert
convert
convert
convert
quantified
quantified
quantified
quantified
quantified
tbl
tbl
tbl
tbl
tbl
words
words
words
words
words
pagesize
pagesize
pagesize
pagesize
pagesize
fn_luid
fn_luid
fn_luid
fn_luid
fn_luid
view
view
view
view
view
pronoun
pronoun
pronoun
pronoun
pronoun
potential_labels
potential_labels
potential_labels
potential_labels
potential_labels
frame
frame
frame
frame
frame
trg_sentence
trg_sentence
trg_sentence
trg_sentence
trg_sentence
lazy
lazy
lazy
lazy
lazy
module
module
module
module
module
freeze
freeze
freeze
freeze
freeze
intensity
intensity
intensity
intensity
intensity
legacy
legacy
legacy
legacy
legacy
mod_address
mod_address
mod_address
mod_address
mod_address
pattern
pattern
pattern
pattern
pattern
realign
realign
realign
realign
realign
state
state
state
state
state
closed
closed
closed
closed
closed
boundary
boundary
boundary
boundary
boundary
ends
ends
ends
ends
ends
columnconfigure
columnconfigure
columnconfigure
columnconfigure
columnconfigure
S
S
S
S
S
hypothesis
hypothesis
hypothesis
hypothesis
hypothesis
key
key
key
key
key
configuration
configuration
configuration
configuration
configuration
original_tag
original_tag
original_tag
original_tag
original_tag
uncurry
uncurry
uncurry
uncurry
uncurry
semtypes
semtypes
semtypes
semtypes
semtypes
equal
equal
equal
equal
equal
include_nt
include_nt
include_nt
include_nt
include_nt
delete_on_gc
delete_on_gc
delete_on_gc
delete_on_gc
delete_on_gc
baseform
baseform
baseform
baseform
baseform
cb
cb
cb
cb
cb
walk
walk
walk
walk
walk
sequences
sequences
sequences
sequences
sequences
table
table
table
table
table
cutlength
cutlength
cutlength
cutlength
cutlength
sentence_readings
sentence_readings
sentence_readings
sentence_readings
sentence_readings
search_leaves
search_leaves
search_leaves
search_leaves
search_leaves
with_shutdown
with_shutdown
with_shutdown
with_shutdown
with_shutdown
quadgram_fd
quadgram_fd
quadgram_fd
quadgram_fd
quadgram_fd
src_sentence
src_sentence
src_sentence
src_sentence
src_sentence
literal
literal
literal
literal
literal
mace4
mace4
mace4
mace4
mace4
describe
describe
describe
describe
describe
alignment_info
alignment_info
alignment_info
alignment_info
alignment_info
semtype
semtype
semtype
semtype
semtype
watcher
watcher
watcher
watcher
watcher
c5
c5
c5
c5
c5
multi
multi
multi
multi
multi
urlbase
urlbase
urlbase
urlbase
urlbase
f2e
f2e
f2e
f2e
f2e
contexts
contexts
contexts
contexts
contexts
align
align
align
align
align
as
as
as
as
as
value
value
value
value
value
size_canvas
size_canvas
size_canvas
size_canvas
size_canvas
cvc
cvc
cvc
cvc
cvc
path_to_model
path_to_model
path_to_model
path_to_model
path_to_model
gamma
gamma
gamma
gamma
gamma
layer
layer
layer
layer
layer
fstructure
fstructure
fstructure
fstructure
fstructure
demo
demo
demo
demo
demo
refs
refs
refs
refs
refs
cacheDepth
cacheDepth
cacheDepth
cacheDepth
cacheDepth
simulate_root
simulate_root
simulate_root
simulate_root
simulate_root
vs
vs
vs
vs
vs
fprefix
fprefix
fprefix
fprefix
fprefix
incr
incr
incr
incr
incr
generic
generic
generic
generic
generic
gramfile
gramfile
gramfile
gramfile
gramfile
classpath
classpath
classpath
classpath
classpath
cross
cross
cross
cross
cross
python
python
python
python
python
childescorpus
childescorpus
childescorpus
childescorpus
childescorpus
vnclass_ids
vnclass_ids
vnclass_ids
vnclass_ids
vnclass_ids
truediv
truediv
truediv
truediv
truediv
parsed_sents
parsed_sents
parsed_sents
parsed_sents
parsed_sents
kneser
kneser
kneser
kneser
kneser
fill
fill
fill
fill
fill
new_assumptions
new_assumptions
new_assumptions
new_assumptions
new_assumptions
n_iixx_tuple
n_iixx_tuple
n_iixx_tuple
n_iixx_tuple
n_iixx_tuple
student
student
student
student
student
iob
iob
iob
iob
iob
expand
expand
expand
expand
expand
concordance
concordance
concordance
concordance
concordance
center
center
center
center
center
neural
neural
neural
neural
neural
i
i
i
i
i
builder
builder
builder
builder
builder
tagged_sentences
tagged_sentences
tagged_sentences
tagged_sentences
tagged_sentences
viterbi
viterbi
viterbi
viterbi
viterbi
wrap_at
wrap_at
wrap_at
wrap_at
wrap_at
command
command
command
command
command
sets
sets
sets
sets
sets
position
position
position
position
position
restore
restore
restore
restore
restore
print_times
print_times
print_times
print_times
print_times
unary
unary
unary
unary
unary
glue
glue
glue
glue
glue
permute
permute
permute
permute
permute
lesk
lesk
lesk
lesk
lesk
web
web
web
web
web
alignment_infos
alignment_infos
alignment_infos
alignment_infos
alignment_infos
tn
tn
tn
tn
tn
point
point
point
point
point
badscore
badscore
badscore
badscore
badscore
add
add
add
add
add
combine
combine
combine
combine
combine
usage
usage
usage
usage
usage
match
match
match
match
match
indvar
indvar
indvar
indvar
indvar
normalise
normalise
normalise
normalise
normalise
suf1
suf1
suf1
suf1
suf1
press
press
press
press
press
immediately
immediately
immediately
immediately
immediately
test_stats
test_stats
test_stats
test_stats
test_stats
height
height
height
height
height
insert
insert
insert
insert
insert
finnish
finnish
finnish
finnish
finnish
stdoutdata
stdoutdata
stdoutdata
stdoutdata
stdoutdata
candc
candc
candc
candc
candc
page
page
page
page
page
collapseRoot
collapseRoot
collapseRoot
collapseRoot
collapseRoot
sequence
sequence
sequence
sequence
sequence
twitter
twitter
twitter
twitter
twitter
other_type
other_type
other_type
other_type
other_type
diff
diff
diff
diff
diff
leaf
leaf
leaf
leaf
leaf
nonempty
nonempty
nonempty
nonempty
nonempty
bindops
bindops
bindops
bindops
bindops
overlap
overlap
overlap
overlap
overlap
shortid
shortid
shortid
shortid
shortid
luannotationset
luannotationset
luannotationset
luannotationset
luannotationset
expansion
expansion
expansion
expansion
expansion
comment_chars
comment_chars
comment_chars
comment_chars
comment_chars
trgtext
trgtext
trgtext
trgtext
trgtext
rare
rare
rare
rare
rare
g_graph
g_graph
g_graph
g_graph
g_graph
extension
extension
extension
extension
extension
longid
longid
longid
longid
longid
column
column
column
column
column
compatible
compatible
compatible
compatible
compatible
dependency
dependency
dependency
dependency
dependency
wildcard_fd
wildcard_fd
wildcard_fd
wildcard_fd
wildcard_fd
transitive
transitive
transitive
transitive
transitive
remove_illegal
remove_illegal
remove_illegal
remove_illegal
remove_illegal
kmeans
kmeans
kmeans
kmeans
kmeans
repp_dirname
repp_dirname
repp_dirname
repp_dirname
repp_dirname
corpus_root
corpus_root
corpus_root
corpus_root
corpus_root
val
val
val
val
val
tree2conllstr
tree2conllstr
tree2conllstr
tree2conllstr
tree2conllstr
target_sents_lens
target_sents_lens
target_sents_lens
target_sents_lens
target_sents_lens
smoothing
smoothing
smoothing
smoothing
smoothing
show_trees
show_trees
show_trees
show_trees
show_trees
var
var
var
var
var
function
function
function
function
function
basic
basic
basic
basic
basic
cur_tok
cur_tok
cur_tok
cur_tok
cur_tok
pk
pk
pk
pk
pk
valuation
valuation
valuation
valuation
valuation
truncation
truncation
truncation
truncation
truncation
count
count
count
count
count
tweetids
tweetids
tweetids
tweetids
tweetids
compute
compute
compute
compute
compute
unicodelines
unicodelines
unicodelines
unicodelines
unicodelines
j
j
j
j
j
vnframe
vnframe
vnframe
vnframe
vnframe
cond_samples
cond_samples
cond_samples
cond_samples
cond_samples
record
record
record
record
record
limit
limit
limit
limit
limit
lvl
lvl
lvl
lvl
lvl
display
display
display
display
display
intersects
intersects
intersects
intersects
intersects
int
int
int
int
int
next_tok
next_tok
next_tok
next_tok
next_tok
sibling
sibling
sibling
sibling
sibling
brill24
brill24
brill24
brill24
brill24
ancestors0
ancestors0
ancestors0
ancestors0
ancestors0
inc
inc
inc
inc
inc
aset_level
aset_level
aset_level
aset_level
aset_level
corpusreader
corpusreader
corpusreader
corpusreader
corpusreader
other
other
other
other
other
lookup
lookup
lookup
lookup
lookup
count_b
count_b
count_b
count_b
count_b
phrase_table
phrase_table
phrase_table
phrase_table
phrase_table
resource_name
resource_name
resource_name
resource_name
resource_name
count_a
count_a
count_a
count_a
count_a
bundle
bundle
bundle
bundle
bundle
readline
readline
readline
readline
readline
searcher
searcher
searcher
searcher
searcher
r1r2
r1r2
r1r2
r1r2
r1r2
ranks
ranks
ranks
ranks
ranks
rule
rule
rule
rule
rule
exprs
exprs
exprs
exprs
exprs
klass
klass
klass
klass
klass
validation
validation
validation
validation
validation
